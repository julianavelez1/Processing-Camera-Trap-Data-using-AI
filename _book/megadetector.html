<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 MegaDetector | Guide for using artificial intelligence platforms for camera-trap data processing</title>
  <meta name="description" content="We aim to provide an overview of the steps required to use platforms that implement artificial intelligence into workflows for processing camera-trap images." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 MegaDetector | Guide for using artificial intelligence platforms for camera-trap data processing" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="We aim to provide an overview of the steps required to use platforms that implement artificial intelligence into workflows for processing camera-trap images." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 MegaDetector | Guide for using artificial intelligence platforms for camera-trap data processing" />
  
  <meta name="twitter:description" content="We aim to provide an overview of the steps required to use platforms that implement artificial intelligence into workflows for processing camera-trap images." />
  

<meta name="author" content="Juliana Velez and John Fieberg" />


<meta name="date" content="2022-08-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="wildlife-insights.html"/>
<link rel="next" href="mlwic2-machine-learning-for-wildlife-image-classification.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.19/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">Guide for using artificial intelligence platforms for camera trap data processing</a></li>

<li class="divider"></li>
<li><a href="index.html#section"></a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="camera-trap-data.html"><a href="camera-trap-data.html"><i class="fa fa-check"></i><b>2</b> Camera-trap data</a></li>
<li class="chapter" data-level="3" data-path="wildlife-insights.html"><a href="wildlife-insights.html"><i class="fa fa-check"></i><b>3</b> Wildlife Insights</a><ul>
<li class="chapter" data-level="3.1" data-path="wildlife-insights.html"><a href="wildlife-insights.html#set-up"><i class="fa fa-check"></i><b>3.1</b> Set-up</a></li>
<li class="chapter" data-level="3.2" data-path="wildlife-insights.html"><a href="wildlife-insights.html#uploadformat-data"><i class="fa fa-check"></i><b>3.2</b> Upload/format data</a></li>
<li class="chapter" data-level="3.3" data-path="wildlife-insights.html"><a href="wildlife-insights.html#uploadenter-metadata"><i class="fa fa-check"></i><b>3.3</b> Upload/enter metadata</a></li>
<li class="chapter" data-level="3.4" data-path="wildlife-insights.html"><a href="wildlife-insights.html#processing-images---ai-module"><i class="fa fa-check"></i><b>3.4</b> Processing images - AI module</a></li>
<li class="chapter" data-level="3.5" data-path="wildlife-insights.html"><a href="wildlife-insights.html#post-ai-image-processing"><i class="fa fa-check"></i><b>3.5</b> Post-AI image processing</a></li>
<li class="chapter" data-level="3.6" data-path="wildlife-insights.html"><a href="wildlife-insights.html#wi-output"><i class="fa fa-check"></i><b>3.6</b> Using AI output</a></li>
<li class="chapter" data-level="3.7" data-path="wildlife-insights.html"><a href="wildlife-insights.html#wi-performance"><i class="fa fa-check"></i><b>3.7</b> Assessing AI performance</a><ul>
<li class="chapter" data-level="3.7.1" data-path="wildlife-insights.html"><a href="wildlife-insights.html#reading-in-data-introduction-to-the-purrr-package"><i class="fa fa-check"></i><b>3.7.1</b> Reading in data, introduction to the Purrr package</a></li>
<li class="chapter" data-level="3.7.2" data-path="wildlife-insights.html"><a href="wildlife-insights.html#removing-duplicated-images"><i class="fa fa-check"></i><b>3.7.2</b> Removing duplicated images</a></li>
<li class="chapter" data-level="3.7.3" data-path="wildlife-insights.html"><a href="wildlife-insights.html#images-with-multiple-observations-of-the-same-species"><i class="fa fa-check"></i><b>3.7.3</b> Images with multiple observations of the same species</a></li>
<li class="chapter" data-level="3.7.4" data-path="wildlife-insights.html"><a href="wildlife-insights.html#merging-computer-and-human-vision-data-sets"><i class="fa fa-check"></i><b>3.7.4</b> Merging computer and human vision data sets</a></li>
<li class="chapter" data-level="3.7.5" data-path="wildlife-insights.html"><a href="wildlife-insights.html#confusion-matrix-and-performance-measures"><i class="fa fa-check"></i><b>3.7.5</b> Confusion matrix and performance measures</a></li>
<li class="chapter" data-level="3.7.6" data-path="wildlife-insights.html"><a href="wildlife-insights.html#confidence-thresholds"><i class="fa fa-check"></i><b>3.7.6</b> Confidence thresholds</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="wildlife-insights.html"><a href="wildlife-insights.html#conclusions"><i class="fa fa-check"></i><b>3.8</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="megadetector.html"><a href="megadetector.html"><i class="fa fa-check"></i><b>4</b> MegaDetector</a><ul>
<li class="chapter" data-level="4.1" data-path="megadetector.html"><a href="megadetector.html#md-upload"><i class="fa fa-check"></i><b>4.1</b> Upload/format data</a></li>
<li class="chapter" data-level="4.2" data-path="megadetector.html"><a href="megadetector.html#md-metadata"><i class="fa fa-check"></i><b>4.2</b> Upload/enter metadata</a></li>
<li class="chapter" data-level="4.3" data-path="megadetector.html"><a href="megadetector.html#md-process"><i class="fa fa-check"></i><b>4.3</b> Process images - AI module</a></li>
<li class="chapter" data-level="4.4" data-path="megadetector.html"><a href="megadetector.html#md-timelapse"><i class="fa fa-check"></i><b>4.4</b> Image processing with Timelapse</a></li>
<li class="chapter" data-level="4.5" data-path="megadetector.html"><a href="megadetector.html#md-output"><i class="fa fa-check"></i><b>4.5</b> Using AI output</a></li>
<li class="chapter" data-level="4.6" data-path="megadetector.html"><a href="megadetector.html#md-performance"><i class="fa fa-check"></i><b>4.6</b> Assessing AI performance</a><ul>
<li class="chapter" data-level="4.6.1" data-path="megadetector.html"><a href="megadetector.html#reading-in-data-introduction-to-the-purrr-package-1"><i class="fa fa-check"></i><b>4.6.1</b> Reading in data, introduction to the Purrr package</a></li>
<li class="chapter" data-level="4.6.2" data-path="megadetector.html"><a href="megadetector.html#format-computer-vision-data-set"><i class="fa fa-check"></i><b>4.6.2</b> Format computer vision data set</a></li>
<li class="chapter" data-level="4.6.3" data-path="megadetector.html"><a href="megadetector.html#md-format-hv"><i class="fa fa-check"></i><b>4.6.3</b> Format human vision data set</a></li>
<li class="chapter" data-level="4.6.4" data-path="megadetector.html"><a href="megadetector.html#merging-computer-and-human-vision-data-sets-1"><i class="fa fa-check"></i><b>4.6.4</b> Merging computer and human vision data sets</a></li>
<li class="chapter" data-level="4.6.5" data-path="megadetector.html"><a href="megadetector.html#confusion-matrix-and-performance-measures-1"><i class="fa fa-check"></i><b>4.6.5</b> Confusion matrix and performance measures</a></li>
<li class="chapter" data-level="4.6.6" data-path="megadetector.html"><a href="megadetector.html#md-thresholds"><i class="fa fa-check"></i><b>4.6.6</b> Confidence thresholds</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="megadetector.html"><a href="megadetector.html#conclusions-1"><i class="fa fa-check"></i><b>4.7</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html"><i class="fa fa-check"></i><b>5</b> MLWIC2: Machine Learning for Wildlife Image Classification</a><ul>
<li class="chapter" data-level="5.1" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#set-up-1"><i class="fa fa-check"></i><b>5.1</b> Set-up</a></li>
<li class="chapter" data-level="5.2" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#format-mlwic2"><i class="fa fa-check"></i><b>5.2</b> Upload/format data</a></li>
<li class="chapter" data-level="5.3" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#mlwic2-ai-module"><i class="fa fa-check"></i><b>5.3</b> Process images - AI module</a></li>
<li class="chapter" data-level="5.4" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#ai-mlwic2"><i class="fa fa-check"></i><b>5.4</b> Assessing AI performance</a><ul>
<li class="chapter" data-level="5.4.1" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#format-human-vision-data-set"><i class="fa fa-check"></i><b>5.4.1</b> Format human vision data set</a></li>
<li class="chapter" data-level="5.4.2" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#format-computer-vision-data-set-1"><i class="fa fa-check"></i><b>5.4.2</b> Format computer vision data set</a></li>
<li class="chapter" data-level="5.4.3" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#merging-computer-and-human-vision-data-sets-2"><i class="fa fa-check"></i><b>5.4.3</b> Merging computer and human vision data sets</a></li>
<li class="chapter" data-level="5.4.4" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#confusion-matrix-and-performance-measures-2"><i class="fa fa-check"></i><b>5.4.4</b> Confusion matrix and performance measures</a></li>
<li class="chapter" data-level="5.4.5" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#confidence-thresholds-1"><i class="fa fa-check"></i><b>5.4.5</b> Confidence thresholds</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#model-training"><i class="fa fa-check"></i><b>5.5</b> Model training</a></li>
<li class="chapter" data-level="5.6" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#classify-trained"><i class="fa fa-check"></i><b>5.6</b> Classify using a trained model</a></li>
<li class="chapter" data-level="5.7" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#conclusions-2"><i class="fa fa-check"></i><b>5.7</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="conservation-ai.html"><a href="conservation-ai.html"><i class="fa fa-check"></i><b>6</b> Conservation AI</a><ul>
<li class="chapter" data-level="6.1" data-path="conservation-ai.html"><a href="conservation-ai.html#set-up-2"><i class="fa fa-check"></i><b>6.1</b> Set-up</a></li>
<li class="chapter" data-level="6.2" data-path="conservation-ai.html"><a href="conservation-ai.html#uploadformat-data-1"><i class="fa fa-check"></i><b>6.2</b> Upload/format data</a></li>
<li class="chapter" data-level="6.3" data-path="conservation-ai.html"><a href="conservation-ai.html#image-tagging"><i class="fa fa-check"></i><b>6.3</b> Image tagging</a></li>
<li class="chapter" data-level="6.4" data-path="conservation-ai.html"><a href="conservation-ai.html#process-images---ai-module"><i class="fa fa-check"></i><b>6.4</b> Process images - AI module</a></li>
<li class="chapter" data-level="6.5" data-path="conservation-ai.html"><a href="conservation-ai.html#conclusions-3"><i class="fa fa-check"></i><b>6.5</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Guide for using artificial intelligence platforms for camera-trap data processing</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="megadetector" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> MegaDetector</h1>
<p>The <a href="https://github.com/microsoft/CameraTraps/blob/master/megadetector.md">MegaDetector (MD)</a> model detects objects (animals, people, and vehicles) in camera trap images, and can be used to separate images into categories of “Empty”, “Animal”, “Human” and “Vehicles” <span class="citation">(Beery, Morris, and Yang <a href="#ref-beery2019efficient">2019</a>)</span>. MD can be run 1. locally by running Python code at the command line, 2. assisted by MegaDetector developers after data are transferred, 3. using a batch processing Application Programming Interface (recommended for large data sets with millions of images), or 4. through <a href="https://camelot-project.readthedocs.io/en/latest/introduction.html">Camelot</a> or <a href="https://subject-assistant.zooniverse.org/#/intro">Zooniverse</a>. To choose one of these options, you can contact MD developers at <a href="mailto:cameratraps@lila.science" class="email">cameratraps@lila.science</a> to see which approach is right for you; this decision will depend on the number of images that you have, whether data can be shared with third parties, and how comfortable you are running Python code <span class="citation">(Beery, Morris, and Yang <a href="#ref-beery2019efficient">2019</a>)</span>. We will describe a workflow for a user that will receive assistance to run the model and integrate MD output with the image processing software <a href="http://saul.cpsc.ucalgary.ca/timelapse/pmwiki.php?n=Main.Download2">Timelapse</a> <span class="citation">(Greenberg, Godin, and Whittington <a href="#ref-greenberg-design">2019</a>)</span>. Sections <a href="megadetector.html#md-upload">4.1</a>-<a href="megadetector.html#md-process">4.3</a> go through the steps required to run MD and interpret its output. Sections <a href="megadetector.html#md-timelapse">4.4</a> and <a href="megadetector.html#md-output">4.5</a> focus on how MD output can be processed in Timelapse and how AI output can be used to accelerate image review and identification by humans. Specifically, AI identifications with high confidence values (i.e., likely to be correct) can be filtered, subset, and subsequently identified by humans using batch operations (see Section <a href="megadetector.html#md-output">4.5</a>). Section <a href="megadetector.html#md-performance">4.6</a> focuses on assessing the performance of MD (MDv4.1) by comparing human labels with the ones provided by MD across different confidence thresholds used for assigning predictions.</p>
<p>MD will continue to be updated and should lead to better model performance over time. A recent MegaDetector version release (MDv5) incorporated additional training data to improve detection of the “vehicle” class, artificial objects (e.g., bait stations), and particular taxa (rodents, reptiles and small birds).</p>
<div id="md-upload" class="section level2">
<h2><span class="header-section-number">4.1</span> Upload/format data</h2>
<p>Requirement of data upload will depend on how the model is run. For local model runs, no data need to be transferred. For assisted model runs, MD developers will provide specific instructions for data transfer. Users using Camelot and Zooniverse must import data directly to each of these platforms.</p>
</div>
<div id="md-metadata" class="section level2">
<h2><span class="header-section-number">4.2</span> Upload/enter metadata</h2>
<p>When using MD, there is no need to enter metadata before processing your data using AI. You will enter metadata during the post-AI image processing stage, when MD output is integrated with other image processing tools such as Timelapse, Camelot or Zooniverse.</p>
</div>
<div id="md-process" class="section level2">
<h2><span class="header-section-number">4.3</span> Process images - AI module</h2>
<p>For assisted model runs, the MD developers will share with you the model output (a JSON file) or a CSV file if requested. This file will contain image filenames (e.g., “A01/01020108.JPG”, where A01 represents the subfolder of a camera trap location and 01020108.JPG is the image filename), maximum confidence values associated with all detections within an image, and the maximum confidence value for each category (animal, person, or vehicle) (Figure <a href="megadetector.html#fig:md-compvision-fig">4.1</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:md-compvision-fig"></span>
<img src="input_figures/md/compvision.png" alt="Predictions provided by Megadetector." width="90%" />
<p class="caption">
Figure 4.1: Predictions provided by Megadetector.
</p>
</div>
</div>
<div id="md-timelapse" class="section level2">
<h2><span class="header-section-number">4.4</span> Image processing with Timelapse</h2>
<p>Timelapse is a software for image processing that can be run in all versions of Microsoft Windows or other operating systems running Windows emulators. Timelapse facilitates image review and annotation of species names or other features of interest (e.g., animals’ sex, behavior, condition, etc.). To run Timelapse, your images must be organized in subfolders (e.g., by study area and camera trap location; Figure <a href="megadetector.html#fig:md-subfolders">4.2</a>). Timelapse software, video tutorials and a detailed manual with all the software features explained can be downloaded here: <a href="http://saul.cpsc.ucalgary.ca/timelapse/pmwiki.php?n=Main.Download2" class="uri">http://saul.cpsc.ucalgary.ca/timelapse/pmwiki.php?n=Main.Download2</a></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:md-subfolders"></span>
<img src="input_figures/md/subfolders.png" alt="Example of image organization in folders and subfolders to load them in Timelapse [@greenberg-timelapse]." width="40%" />
<p class="caption">
Figure 4.2: Example of image organization in folders and subfolders to load them in Timelapse <span class="citation">(Greenberg <a href="#ref-greenberg-timelapse">2020</a>)</span>.
</p>
</div>
<p>Before using Timelapse, you will need to create a data schema (i.e., a template with a .tdb file extension) that identifies the data fields that will be recorded when processing your camera trap data (e.g., species name, sex, behavior, etc.). This step can be accomplished by using the Timelapse Template Editor that is downloaded along with Timelapse. The Template Editor allows you to create the .tdb file that will be read in Timelapse and will adjust the software image processing interface to capture the different data fields you specify in the .tdb file <span class="citation">(Greenberg <a href="#ref-greenberg-timelapse">2020</a>)</span>.</p>
<p>Once photos are imported to Timelapse, you can review them using different processing tools provided by the software. The Timelapse manual <span class="citation">(Greenberg <a href="#ref-greenberg-timelapse">2020</a>)</span> and documentation about the software design <span class="citation">(Greenberg, Godin, and Whittington <a href="#ref-greenberg-design">2019</a>)</span> describe in detail the processing tools available in the software, which include features to:</p>
<ul>
<li>Magnify images and explore image difference extraction tools (e.g., to identify small animals that are otherwise difficult to spot).</li>
<li>Select multiple images quickly from small thumbnails and classify them all at once.</li>
<li>Automate data entry via metadata extraction (time/date, filename, temperature sensed by the camera) and copy annotated information to other images.</li>
<li>Sort images by date, species or any other annotated feature, to easily review and verify this information.</li>
</ul>
</div>
<div id="md-output" class="section level2">
<h2><span class="header-section-number">4.5</span> Using AI output</h2>
<p>To integrate MD output with Timelapse, you will need to have the same folder and subfolder structure (Figure <a href="megadetector.html#fig:md-subfolders">4.2</a>) that you used when running MD. Using the same folder structure allows Timelapse to match each image with MD output using relative paths associated with each filename.</p>
<p>In Timelapse, you must activate the option for working with image recognition data and import computer vision results stored in the JSON file <span class="citation">(Greenberg <a href="#ref-greenberg-timelapse">2020</a>)</span>. You will see bounding boxes that can facilitate image review once the automatic image recognition is activated.</p>
<p>To use AI results to accelerate image review, you can filter MD output categories detected with high confidence levels that are likely correct. To do that, you must provide a confidence range to accept predictions made by computer vision (Figure <a href="megadetector.html#fig:md-confidence-value">4.3</a>). For example, if you choose “Empty” as the detected entity and a high confidence range (e.g, from 0.65 to 1.00), your data set will be filtered to display images predicted as “Empty” by MD and likely to be correct.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:md-confidence-value"></span>
<img src="input_figures/md/confidence_value.png" alt="When activating the use of AI detections, users can filter which images are displayed depending on the range of confidence values provided [@greenberg-timelapse]." width="80%" />
<p class="caption">
Figure 4.3: When activating the use of AI detections, users can filter which images are displayed depending on the range of confidence values provided <span class="citation">(Greenberg <a href="#ref-greenberg-timelapse">2020</a>)</span>.
</p>
</div>
<p>After subsetting images to be displayed depending on their confidence values, you can easily inspect images in the overview mode in Timelapse and select multiple images at a time and assign an “Empty” category to them if the AI output is correct (Figure <a href="megadetector.html#fig:md-overview-timelapse">4.4</a>). If AI output is not correct, you can edit those classifications.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:md-overview-timelapse"></span>
<img src="input_figures/md/overview.png" alt="Timelapse overview mode where users can perform bulk actions (e.g., selection of multiple images) to accept or edit AI predictions [@greenberg-timelapse]." width="80%" />
<p class="caption">
Figure 4.4: Timelapse overview mode where users can perform bulk actions (e.g., selection of multiple images) to accept or edit AI predictions <span class="citation">(Greenberg <a href="#ref-greenberg-timelapse">2020</a>)</span>.
</p>
</div>
<p>After, processing images with Timelapse, you can export the data as a CSV File. This file (<code>TimelapseData.csv</code>) will contain all the data entries that you specified in the template (Figure <a href="megadetector.html#fig:output-timelapse">4.5</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:output-timelapse"></span>
<img src="input_figures/md/output.png" alt="Output contained in a CSV file exported from Timelapse software [@greenberg-timelapse]." width="80%" />
<p class="caption">
Figure 4.5: Output contained in a CSV file exported from Timelapse software <span class="citation">(Greenberg <a href="#ref-greenberg-timelapse">2020</a>)</span>.
</p>
</div>
</div>
<div id="md-performance" class="section level2">
<h2><span class="header-section-number">4.6</span> Assessing AI performance</h2>
<p>Before exploring model performance with your data, let us recapitulate. MD runs AI models and outputs broad categories of predictions for images (in a JSON file). These AI predictions can be integrated with Timelapse to further process camera trap images (i.e., identifying images with the help of AI output). However, if you have previously classified images (e.g., identified using your software or platform of preference), you can explore MD performance before integrating AI results using Timelapse.</p>
<p>To evaluate MD performance, you will need to 1) classify a subset of your images and export the classification results to a CSV file (containing at minimum, the image filename, camera location and species name), and 2) obtain MD output in CSV format. You can then follow the steps below to evaluate the performance of MD’s AI model. We also discuss how one can select an appropriate confidence threshold for filtering images to accelerate the image review process (e.g., by focusing only on images that likely contain an animal).</p>
<div id="reading-in-data-introduction-to-the-purrr-package-1" class="section level3">
<h3><span class="header-section-number">4.6.1</span> Reading in data, introduction to the Purrr package</h3>
<p>Below, we demonstrate a step-by-step workflow for how to get MD output into R, join computer and human vision identifications, and estimate model performance metrics for each class. Throughout, we will use the <code>purrr</code> package in R <span class="citation">(Henry and Wickham <a href="#ref-purrr">2020</a>; R Core Team <a href="#ref-R-base">2021</a>)</span> to repeatedly apply the same function to objects in a list or column in a nested data frame efficiently and without the need for writing loops. Readers unfamiliar with <code>purrr</code> syntax, may want to view one or more of the tutorials, below, or make use of the <a href="https://github.com/rstudio/cheatsheets/blob/master/purrr.pdf">purrr cheat sheet</a>.</p>
<ul>
<li><a href="http://www.rebeccabarter.com/blog/2019-08-19_purrr/" class="uri">http://www.rebeccabarter.com/blog/2019-08-19_purrr/</a></li>
<li><a href="https://www.r-bloggers.com/2020/05/one-stop-tutorial-on-purrr-package-in-r/" class="uri">https://www.r-bloggers.com/2020/05/one-stop-tutorial-on-purrr-package-in-r/</a></li>
<li><a href="https://jennybc.github.io/purrr-tutorial/index.html" class="uri">https://jennybc.github.io/purrr-tutorial/index.html</a></li>
</ul>
<ol style="list-style-type: decimal">
<li><p>Once you finish the identification of a subset of your images using your platform of preference, export your classifications as a CSV file and name it as <code>images_hv.csv</code>. The other CSV file containing the MD results can be named as <code>images_cv.csv</code>.</p></li>
<li><p>Create a data folder to store your two CSV files <code>images_cv.csv</code> and <code>images_hv.csv</code> that refer to classifications of computer and human vision, respectively (note, we provide an example of both files with the repository associated with this guide named <code>images_cv_jan2020.csv</code> and <code>images_hv_jan2020.csv</code>).</p></li>
<li><p>Process the two data files using the R code provided below.</p></li>
</ol>
<p>First, we load required libraries and open files.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" data-line-number="1"><span class="kw">library</span>(tidyverse) <span class="co"># for data wrangling and visualization, includes dplyr and purrr</span></a>
<a class="sourceLine" id="cb32-2" data-line-number="2"><span class="kw">library</span>(here) <span class="co"># to allow use of relative paths</span></a></code></pre></div>
<p>Next, we tell R the path (i.e., directory name) that holds our files. We will use the <code>here</code> package <span class="citation">(Müller <a href="#ref-here">2017</a>)</span> to tell R that our files live in the “./data/md” directory. You may, alternatively, type in the full path to the file folder or a relative path from the root directory if you are using a project in RStudio.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" data-line-number="1"><span class="co"># Create filefolder&#39;s path. This should point to the folder name</span></a>
<a class="sourceLine" id="cb33-2" data-line-number="2"><span class="co"># where you stored your CSV files, one with classifications of some of your images</span></a>
<a class="sourceLine" id="cb33-3" data-line-number="3"><span class="co"># and the other with MD output</span></a>
<a class="sourceLine" id="cb33-4" data-line-number="4">filesfolder &lt;-<span class="st"> </span><span class="kw">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;md&quot;</span>) </a>
<a class="sourceLine" id="cb33-5" data-line-number="5">filesfolder</a></code></pre></div>
<pre><code>## [1] &quot;/Users/julianavelez/Documents/GitHub/Processing-Camera-Trap-Data-using-AI/data/md&quot;</code></pre>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" data-line-number="1"><span class="co"># List your files contained in the filesfolder directory. This code will</span></a>
<a class="sourceLine" id="cb35-2" data-line-number="2"><span class="co"># list all your CSV files (i.e., images_cv.csv and images_hv.csv)</span></a>
<a class="sourceLine" id="cb35-3" data-line-number="3">files &lt;-<span class="st"> </span><span class="kw">dir</span>(filesfolder, <span class="dt">pattern =</span> <span class="st">&quot;*.csv&quot;</span>) </a>
<a class="sourceLine" id="cb35-4" data-line-number="4">files</a></code></pre></div>
<pre><code>## [1] &quot;images_cv_jan2020.csv&quot; &quot;images_hv_jan2020.csv&quot;</code></pre>
<p>We then use the <code>map</code> function in the <code>purrr</code> library to read in all of the files and store them in a list object named <code>mycsv</code>. The first argument to <code>map</code> is a list (here, <code>files</code>) which is “piped in” using <code>%&gt;%</code> from the <code>magrittr</code> package <span class="citation">(Bache and Wickham <a href="#ref-magrittr">2020</a>)</span>. Pipes (<code>%&gt;%</code>) provide a way to execute a sequence of data operations, organized so that the operations can be read from left to right (e.g., “Take the set of files and then read them in using <code>read_csv</code>”). The second argument to <code>map</code> is a function, in this case <code>read_csv</code>, to be applied to the list. The <code>map</code> function iterates over the two files stored in the <code>files</code> object, reads in the data files and then stores them in a new list named <code>mycsv.</code> We use <code>~</code> to refer to our function and use <code>.x</code> to refer to the list object that is passed to the function as an additional argument.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" data-line-number="1"><span class="co"># Read both CSV files</span></a>
<a class="sourceLine" id="cb37-2" data-line-number="2">mycsv &lt;-<span class="st"> </span>files <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb37-3" data-line-number="3"><span class="st">  </span><span class="kw">map</span>(<span class="op">~</span><span class="kw">read_csv</span>(<span class="kw">file.path</span>(filesfolder, .x)))</a>
<a class="sourceLine" id="cb37-4" data-line-number="4"></a>
<a class="sourceLine" id="cb37-5" data-line-number="5"><span class="co"># Inspect how the data sets look like</span></a>
<a class="sourceLine" id="cb37-6" data-line-number="6">mycsv </a></code></pre></div>
<pre><code>## [[1]]
## # A tibble: 112,247 × 7
##    image_path               max_confidence detections max_conf_animal max_conf_person
##    &lt;chr&gt;                             &lt;dbl&gt; &lt;lgl&gt;                &lt;dbl&gt;           &lt;dbl&gt;
##  1 jan2020/A01/01080001.JPG          0.998 NA                  NA               0.998
##  2 jan2020/A01/01080002.JPG          0.97  NA                  NA               0.97 
##  3 jan2020/A01/01080003.JPG          0.996 NA                  NA               0.996
##  4 jan2020/A01/01080004.JPG          0.985 NA                   0.202           0.985
##  5 jan2020/A01/01080005.JPG          0.939 NA                   0.209           0.939
##  6 jan2020/A01/01080006.JPG          0.996 NA                  NA               0.996
##  7 jan2020/A01/01080007.JPG          0.999 NA                  NA               0.999
##  8 jan2020/A01/01080008.JPG          0.997 NA                  NA               0.997
##  9 jan2020/A01/01080009.JPG          0.914 NA                   0.428           0.914
## 10 jan2020/A01/01080010.JPG          0.992 NA                  NA               0.992
## # … with 112,237 more rows, and 2 more variables: max_conf_group &lt;dbl&gt;,
## #   max_conf_vehicle &lt;lgl&gt;
## 
## [[2]]
## # A tibble: 103,053 × 5
##    filename         timestamp           image_id           common_name    sp_num
##    &lt;chr&gt;            &lt;dttm&gt;              &lt;chr&gt;              &lt;chr&gt;           &lt;dbl&gt;
##  1 N25/03310082.JPG 2020-03-31 14:28:14 902b671f-58b9-4cb… Collared Pecc…      1
##  2 N29/03310288.JPG 2020-03-31 06:49:17 e727dc42-5ebb-46a… Collared Pecc…      1
##  3 A06/06020479.JPG 2020-06-02 08:12:17 db3c3213-5ad9-4bf… Black Agouti        1
##  4 A02/03100387.JPG 2020-03-10 06:58:27 c7e33138-08ac-461… Unknown speci…      1
##  5 A04/04180034.JPG 2020-04-18 05:37:56 52f77e0c-7023-408… Bos Species         1
##  6 A06/03020343.JPG 2020-03-02 12:00:45 94a5b596-1685-40a… Spix&#39;s Guan         1
##  7 A06/06190148.JPG 2020-06-19 11:40:33 063c0153-d8fd-46b… White-lipped …      1
##  8 A06/06250315.JPG 2020-06-25 07:08:56 4b6f9c4e-e8bb-4a9… Lowland Tapir       1
##  9 A07/05090248.JPG 2020-05-09 15:05:11 15c4e9f4-7a68-4bd… Domestic Horse      1
## 10 A09/02030454.JPG 2020-02-03 10:34:41 cb56ac06-6520-47c… Bos Species         1
## # … with 103,043 more rows</code></pre>
</div>
<div id="format-computer-vision-data-set" class="section level3">
<h3><span class="header-section-number">4.6.2</span> Format computer vision data set</h3>
<p>Columns of interest in the the MD data set include:</p>
<ul>
<li><code>filename</code>: contains camera location and filename (e.g., A01/01010461.JPG).</li>
<li><code>max_confidence</code>: contains the maximum confidence value found for a detection in an image.</li>
<li><code>max_conf_animal</code>, <code>max_conf_person</code>, <code>max_conf_group</code>, <code>max_conf_vehicle</code>: each of these columns contain a confidence value associated with a prediction by computer vision for the different classes.</li>
</ul>
<p>We begin by creating a <code>max_conf_blank</code> variable, which we will use to identify blank images. We assign a value of 1 to this variable whenever the observation has missing values for all of the other <code>max_conf</code> variables.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb39-1" data-line-number="1">cv_wide &lt;-<span class="st"> </span>mycsv <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb39-2" data-line-number="2"><span class="st">  </span><span class="kw">pluck</span>(<span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co">#extract the computer vision images_cv.csv file</span></a>
<a class="sourceLine" id="cb39-3" data-line-number="3"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">filename =</span> image_path) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb39-4" data-line-number="4"><span class="st">  </span><span class="kw">group_by</span>(filename) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb39-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">max_conf_blank =</span> <span class="kw">case_when</span>(<span class="kw">sum</span>(<span class="kw">is.na</span>(max_conf_animal),</a>
<a class="sourceLine" id="cb39-6" data-line-number="6">                               <span class="kw">is.na</span>(max_conf_person), </a>
<a class="sourceLine" id="cb39-7" data-line-number="7">                               <span class="kw">is.na</span>(max_conf_group), </a>
<a class="sourceLine" id="cb39-8" data-line-number="8">                               <span class="kw">is.na</span>(max_conf_vehicle)) <span class="op">==</span><span class="st"> </span><span class="dv">4</span> <span class="op">~</span><span class="st"> </span><span class="dv">1</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb39-9" data-line-number="9"><span class="st">  </span><span class="kw">ungroup</span>()</a></code></pre></div>
<p>MD can detect and classify more than one object in an image, and each object will be assigned its own confidence value. We want to keep each of these classifications in a separate row. To do that, we first change the data set from “wide” to “long” format using the <code>pivot_longer</code> function <span class="citation">(Wickham and Henry <a href="#ref-R-tidyr">2018</a>)</span>. This function will create two new variables, <code>name</code> and <code>value</code>, that will hold the classification (“Human”, “Animal”, “Vehicle”, “Blank”) and associated confidence values, respectively.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" data-line-number="1">cv_long &lt;-<span class="st"> </span>cv_wide <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb40-2" data-line-number="2"><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>detections) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb40-3" data-line-number="3"><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="kw">c</span>(<span class="st">&quot;max_conf_animal&quot;</span>,</a>
<a class="sourceLine" id="cb40-4" data-line-number="4">                 <span class="st">&quot;max_conf_person&quot;</span>, </a>
<a class="sourceLine" id="cb40-5" data-line-number="5">                 <span class="st">&quot;max_conf_group&quot;</span>, </a>
<a class="sourceLine" id="cb40-6" data-line-number="6">                 <span class="st">&quot;max_conf_vehicle&quot;</span>, </a>
<a class="sourceLine" id="cb40-7" data-line-number="7">                 <span class="st">&quot;max_conf_blank&quot;</span>)) </a>
<a class="sourceLine" id="cb40-8" data-line-number="8"></a>
<a class="sourceLine" id="cb40-9" data-line-number="9">cv_long</a></code></pre></div>
<pre><code>## # A tibble: 561,235 × 4
##    filename                 max_confidence name              value
##    &lt;chr&gt;                             &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;
##  1 jan2020/A01/01080001.JPG          0.998 max_conf_animal  NA    
##  2 jan2020/A01/01080001.JPG          0.998 max_conf_person   0.998
##  3 jan2020/A01/01080001.JPG          0.998 max_conf_group   NA    
##  4 jan2020/A01/01080001.JPG          0.998 max_conf_vehicle NA    
##  5 jan2020/A01/01080001.JPG          0.998 max_conf_blank   NA    
##  6 jan2020/A01/01080002.JPG          0.97  max_conf_animal  NA    
##  7 jan2020/A01/01080002.JPG          0.97  max_conf_person   0.97 
##  8 jan2020/A01/01080002.JPG          0.97  max_conf_group   NA    
##  9 jan2020/A01/01080002.JPG          0.97  max_conf_vehicle NA    
## 10 jan2020/A01/01080002.JPG          0.97  max_conf_blank   NA    
## # … with 561,225 more rows</code></pre>
<p>Next, we drop all rows where the confidence value is equal to “NA” and rename our classification variable to <code>class</code>. Additionally, we remove images with the “Vehicle” and “Human” classes.</p>
<p>To simplify things, we also change the “Group” label to “Animal”. We do this for 3 reasons: 1) we found that there were very few “Group” classifications in our data set; 2) these predictions were not very accurate; and 3) MD will most often be used to separate blank images from those that have at least one animal present, and thus, the “Group” label is not all that informative.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb42-1" data-line-number="1">cv &lt;-<span class="st"> </span>cv_long <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb42-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(<span class="kw">is.na</span>(value) <span class="op">!=</span><span class="st"> </span><span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb42-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">name =</span> <span class="kw">replace</span>(name, name <span class="op">==</span><span class="st"> &quot;max_conf_blank&quot;</span> , <span class="st">&quot;Blank&quot;</span>), </a>
<a class="sourceLine" id="cb42-4" data-line-number="4">         <span class="dt">name =</span> <span class="kw">replace</span>(name, name <span class="op">==</span><span class="st"> &quot;max_conf_animal&quot;</span>, <span class="st">&quot;Animal&quot;</span>), </a>
<a class="sourceLine" id="cb42-5" data-line-number="5">         <span class="dt">name =</span> <span class="kw">replace</span>(name, name <span class="op">==</span><span class="st"> &quot;max_conf_person&quot;</span>, <span class="st">&quot;Human&quot;</span>), </a>
<a class="sourceLine" id="cb42-6" data-line-number="6">         <span class="dt">name =</span> <span class="kw">replace</span>(name, name <span class="op">==</span><span class="st"> &quot;max_conf_group&quot;</span>, <span class="st">&quot;Animal&quot;</span>), </a>
<a class="sourceLine" id="cb42-7" data-line-number="7">         <span class="dt">name =</span> <span class="kw">replace</span>(name, name <span class="op">==</span><span class="st"> &quot;max_conf_vehicle&quot;</span>, <span class="st">&quot;Vehicle&quot;</span>)) <span class="op">%&gt;%</span><span class="st">  </span></a>
<a class="sourceLine" id="cb42-8" data-line-number="8"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">class =</span> name) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb42-9" data-line-number="9"><span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span>class <span class="op">%in%</span><span class="st"> &quot;Human&quot;</span> <span class="op">&amp;</span><span class="st"> </span><span class="op">!</span>class <span class="op">%in%</span><span class="st"> &quot;Vehicle&quot;</span>)</a></code></pre></div>
<p>Changing the “Group” label to “Animal” results in some images having multiple predictions of “Animal” for the same image. In these cases, we use the <code>top_n</code> function to select the record with the highest confidence value <span class="citation">(Wickham et al. <a href="#ref-R-dplyr">2019</a>)</span>.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb43-1" data-line-number="1">cv &lt;-<span class="st"> </span>cv <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb43-2" data-line-number="2"><span class="st">        </span><span class="kw">group_by</span>(filename, class) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb43-3" data-line-number="3"><span class="st">        </span><span class="kw">top_n</span>(<span class="dv">1</span>, value) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># keep highest value of same class</span></a>
<a class="sourceLine" id="cb43-4" data-line-number="4"><span class="st">        </span><span class="kw">group_by</span>(filename, class) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb43-5" data-line-number="5"><span class="st">        </span><span class="kw">distinct</span>(filename, class, value, <span class="dt">.keep_all =</span> <span class="ot">TRUE</span>) <span class="co"># for filenames with the same confidence value, keep a single record</span></a></code></pre></div>
<p>Comparing output from human and computer vision also requires that the classification variables have the same levels attribute. We first create a vector, <code>all_levels</code>, containing the names of the classes. Then, we use the <code>factor</code> function <span class="citation">(R Core Team <a href="#ref-R-base">2021</a>)</span> to convert common names into factor classes and assign the levels to the <code>class</code> column.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" data-line-number="1"><span class="co"># Create a vector with levels of predicted categories</span></a>
<a class="sourceLine" id="cb44-2" data-line-number="2">all_levels &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Animal&quot;</span>, <span class="st">&quot;Blank&quot;</span>)</a>
<a class="sourceLine" id="cb44-3" data-line-number="3"></a>
<a class="sourceLine" id="cb44-4" data-line-number="4"><span class="co"># Assign the levels attribute to the class column</span></a>
<a class="sourceLine" id="cb44-5" data-line-number="5">cv<span class="op">$</span>class &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">as.character</span>(cv<span class="op">$</span>class, <span class="dt">levels =</span> all_levels))</a></code></pre></div>
<p>Lastly, we add a variable that will indicate if there are multiple detections within the same image.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" data-line-number="1">cv &lt;-<span class="st"> </span>cv <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb45-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(filename) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb45-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">multiple_det =</span> <span class="kw">n</span>() <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb45-4" data-line-number="4"><span class="st">  </span><span class="kw">select</span>(filename,  class, value, multiple_det) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb45-5" data-line-number="5"><span class="st">  </span><span class="kw">ungroup</span>()</a></code></pre></div>
</div>
<div id="md-format-hv" class="section level3">
<h3><span class="header-section-number">4.6.3</span> Format human vision data set</h3>
<p>The human vision data set (<code>ìmages_hv_jan2020.csv</code>) was previously cleaned to remove duplicated records and to summarize multiple rows that reference animals of the same species identified in the same image (see Chapter <a href="wildlife-insights.html#wildlife-insights">3</a>) for details about these steps).</p>
<p>We begin by inspecting all the species names contained in the human vision data set using the <code>unique</code> function <span class="citation">(R Core Team <a href="#ref-R-base">2021</a>)</span>. We will eventually need to create a variable that can be compared to MD output (i.e., broad classes identifying “Blank” and “Animal”).</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" data-line-number="1">hv_sp &lt;-<span class="st"> </span>mycsv <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb46-2" data-line-number="2"><span class="st">  </span><span class="kw">pluck</span>(<span class="dv">2</span>) <span class="co"># select human vision data frame</span></a>
<a class="sourceLine" id="cb46-3" data-line-number="3">  </a>
<a class="sourceLine" id="cb46-4" data-line-number="4"><span class="co"># check all species present in the data set</span></a>
<a class="sourceLine" id="cb46-5" data-line-number="5"><span class="kw">unique</span>(hv_sp<span class="op">$</span>common_name) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sort</span>()</a></code></pre></div>
<pre><code>##  [1] &quot;Alouatta Species&quot;             &quot;Amazonian Motmot&quot;            
##  [3] &quot;Ants&quot;                         &quot;Bird&quot;                        
##  [5] &quot;Black Agouti&quot;                 &quot;Blank&quot;                       
##  [7] &quot;Bos Species&quot;                  &quot;Bush Dog&quot;                    
##  [9] &quot;Caprimulgidae Family&quot;         &quot;Capybara&quot;                    
## [11] &quot;Cervidae Family&quot;              &quot;Collared Peccary&quot;            
## [13] &quot;Common Green Iguana&quot;          &quot;Crab-eating Fox&quot;             
## [15] &quot;Crestless Curassow&quot;           &quot;Dasypus Species&quot;             
## [17] &quot;Domestic Dog&quot;                 &quot;Domestic Horse&quot;              
## [19] &quot;Fasciated Tiger-heron&quot;        &quot;Giant Anteater&quot;              
## [21] &quot;Giant Armadillo&quot;              &quot;Giant Otter&quot;                 
## [23] &quot;Insect&quot;                       &quot;Jaguar&quot;                      
## [25] &quot;Jaguarundi&quot;                   &quot;Lizards and Snakes&quot;          
## [27] &quot;Lowland Tapir&quot;                &quot;Mammal&quot;                      
## [29] &quot;Margarita Island Capuchin&quot;    &quot;Margay&quot;                      
## [31] &quot;Northern Amazon Red Squirrel&quot; &quot;Ocelot&quot;                      
## [33] &quot;Ornate Tití Monkey&quot;           &quot;Pecari Species&quot;              
## [35] &quot;Possum Family&quot;                &quot;Puma&quot;                        
## [37] &quot;Red Brocket&quot;                  &quot;Rodent&quot;                      
## [39] &quot;Saimiri Species&quot;              &quot;South American Coati&quot;        
## [41] &quot;Southern Tamandua&quot;            &quot;Spix&#39;s Guan&quot;                 
## [43] &quot;Spotted Paca&quot;                 &quot;Tayra&quot;                       
## [45] &quot;Turkey Vulture&quot;               &quot;Turtle Order&quot;                
## [47] &quot;Unknown species&quot;              &quot;Weasel Family&quot;               
## [49] &quot;White-lipped Peccary&quot;         &quot;White-tailed Deer&quot;</code></pre>
<p>MD output represents filenames as “deployment/camera_location/image_filename”, based on folder structure. We add the deployment name to the <code>filename</code> variable in human vision output so that it matches the format of the MD data set. These steps will allow us to later join our human and computer vision data sets using the common variable, <code>filename</code>.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb48-1" data-line-number="1">hv_sp &lt;-<span class="st"> </span>hv_sp <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb48-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">filename =</span> <span class="kw">paste0</span>(<span class="st">&quot;jan2020/&quot;</span>, filename))</a></code></pre></div>
<p>We use the <code>case_when</code> function <span class="citation">(Wickham et al. <a href="#ref-R-dplyr">2019</a>)</span> to implement multiple conditional statements to create a variable, <code>class_hv</code>, containing the classes found in MD output. We select the columns of interest, including a newly created variable (<code>multiple_det</code>) that will keep track of images that have two or more species present in the same image, each recorded in a different row. For the multiple detections, we keep a single row using the <code>distinct</code> function <span class="citation">(Wickham et al. <a href="#ref-R-dplyr">2019</a>)</span>.</p>
<p>We also assign a levels attribute to the <code>class</code> variable in human vision so that it is comparable to the <code>class</code> variable in the computer vision data set.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb49-1" data-line-number="1">hv &lt;-<span class="st"> </span>hv_sp <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb49-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(filename, timestamp) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb49-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">multiple_det =</span> <span class="kw">n</span>() <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># create multiple detections column (TRUE/FALSE).</span></a>
<a class="sourceLine" id="cb49-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">class =</span> <span class="kw">case_when</span>(common_name <span class="op">==</span><span class="st"> &quot;Blank&quot;</span> <span class="op">~</span><span class="st"> </span>common_name,</a>
<a class="sourceLine" id="cb49-5" data-line-number="5">                           <span class="ot">TRUE</span> <span class="op">~</span><span class="st"> &quot;Animal&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb49-6" data-line-number="6"><span class="st">  </span><span class="kw">select</span>(filename, timestamp, class, multiple_det)</a>
<a class="sourceLine" id="cb49-7" data-line-number="7"></a>
<a class="sourceLine" id="cb49-8" data-line-number="8">hv &lt;-<span class="st"> </span>hv <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb49-9" data-line-number="9"><span class="st">  </span><span class="kw">group_by</span>(filename, class) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb49-10" data-line-number="10"><span class="st">  </span><span class="kw">distinct</span>(filename, class, <span class="dt">.keep_all =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb49-11" data-line-number="11"><span class="st">  </span><span class="kw">ungroup</span>()</a>
<a class="sourceLine" id="cb49-12" data-line-number="12"></a>
<a class="sourceLine" id="cb49-13" data-line-number="13"><span class="co"># Assign the levels attribute to the class column</span></a>
<a class="sourceLine" id="cb49-14" data-line-number="14">hv<span class="op">$</span>class &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">as.character</span>(hv<span class="op">$</span>class), <span class="dt">levels =</span> all_levels)</a></code></pre></div>
</div>
<div id="merging-computer-and-human-vision-data-sets-1" class="section level3">
<h3><span class="header-section-number">4.6.4</span> Merging computer and human vision data sets</h3>
<p>Now that we have the same format for both human and computer vision data sets, we can use various “joins” <span class="citation">(Wickham et al. <a href="#ref-R-dplyr">2019</a>)</span> to merge the two data sets together so that we can evaluate the accuracy of MD. First, however, we will eliminate any images that were not processed by both humans and AI.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb50-1" data-line-number="1"><span class="co"># Determine which images have been viewed by both methods</span></a>
<a class="sourceLine" id="cb50-2" data-line-number="2">ind1 &lt;-<span class="st"> </span>cv<span class="op">$</span>filename <span class="op">%in%</span><span class="st"> </span>hv<span class="op">$</span>filename <span class="co"># in both</span></a>
<a class="sourceLine" id="cb50-3" data-line-number="3">ind2 &lt;-<span class="st"> </span>hv<span class="op">$</span>filename <span class="op">%in%</span><span class="st"> </span>cv<span class="op">$</span>filename <span class="co"># in both</span></a>
<a class="sourceLine" id="cb50-4" data-line-number="4"></a>
<a class="sourceLine" id="cb50-5" data-line-number="5">cv &lt;-<span class="st"> </span>cv[ind1,] <span class="co"># eliminate images not processed by hv</span></a>
<a class="sourceLine" id="cb50-6" data-line-number="6">hv &lt;-<span class="st"> </span>hv[ind2,] <span class="co"># eliminate images not processed by cv</span></a>
<a class="sourceLine" id="cb50-7" data-line-number="7"></a>
<a class="sourceLine" id="cb50-8" data-line-number="8"><span class="co"># Number of photos eliminated</span></a>
<a class="sourceLine" id="cb50-9" data-line-number="9"><span class="kw">sum</span>(ind1 <span class="op">!=</span><span class="st"> </span><span class="ot">TRUE</span>) <span class="co"># in cv but not in hv</span></a></code></pre></div>
<pre><code>## [1] 5397</code></pre>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" data-line-number="1"><span class="kw">sum</span>(ind2 <span class="op">!=</span><span class="st"> </span><span class="ot">TRUE</span>) <span class="co"># in hv but not in cv</span></a></code></pre></div>
<pre><code>## [1] 1168</code></pre>
<p>Now, we can use:</p>
<ul>
<li>an <code>inner_join</code> with <code>filename</code> and <code>class</code> to determine images that have correct predictions (i.e., images with the same class assigned by computer and human vision)</li>
<li>an <code>anti_join</code> with <code>filename</code> and <code>class</code> to determine which records in the human vision data set have incorrect predictions from computer vision.</li>
<li>an <code>anti_join</code> with <code>filename</code> and <code>class</code> to determine which records in the computer vision data set have incorrect predictions.</li>
</ul>
<p>We assume the classifications from human vision to be correct and distinguish them from MD predictions. The MD predictions will be correct if they match a class assigned by human vision for a particular record and incorrect if the classes assigned by the two visions differ.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" data-line-number="1"><span class="co"># correct predictions</span></a>
<a class="sourceLine" id="cb54-2" data-line-number="2">matched &lt;-<span class="st"> </span>cv <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb54-3" data-line-number="3"><span class="st">  </span><span class="kw">inner_join</span>(<span class="dt">y =</span> hv, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&quot;filename&quot;</span>, <span class="st">&quot;class&quot;</span>), <span class="dt">suffix =</span> <span class="kw">c</span>(<span class="st">&quot;_cv&quot;</span>, <span class="st">&quot;_hv&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb54-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">class_hv =</span> class) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb54-5" data-line-number="5"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">class_cv =</span> class) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb54-6" data-line-number="6"><span class="st">  </span><span class="kw">select</span>(filename, value, class_cv, class_hv, multiple_det_cv, multiple_det_hv)</a>
<a class="sourceLine" id="cb54-7" data-line-number="7"></a>
<a class="sourceLine" id="cb54-8" data-line-number="8"><span class="co"># incorrect predictions in hv set</span></a>
<a class="sourceLine" id="cb54-9" data-line-number="9">hv_only &lt;-<span class="st"> </span>hv <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb54-10" data-line-number="10"><span class="st">  </span><span class="kw">anti_join</span>(<span class="dt">y =</span> cv, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&quot;filename&quot;</span>, <span class="st">&quot;class&quot;</span>), <span class="dt">suffix =</span> <span class="kw">c</span>(<span class="st">&quot;_hv&quot;</span>, <span class="st">&quot;_cv&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb54-11" data-line-number="11"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">class_hv =</span> class) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb54-12" data-line-number="12"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">multiple_det_hv =</span> multiple_det)</a>
<a class="sourceLine" id="cb54-13" data-line-number="13">  </a>
<a class="sourceLine" id="cb54-14" data-line-number="14"><span class="co"># incorrect predictions in cv set</span></a>
<a class="sourceLine" id="cb54-15" data-line-number="15">cv_only&lt;-<span class="st"> </span>cv <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb54-16" data-line-number="16"><span class="st">  </span><span class="kw">anti_join</span>(<span class="dt">y =</span> hv, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&quot;filename&quot;</span>, <span class="st">&quot;class&quot;</span>), <span class="dt">suffix =</span> <span class="kw">c</span>(<span class="st">&quot;_cv&quot;</span>, <span class="st">&quot;_hv&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb54-17" data-line-number="17"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">class_cv =</span> class)</a></code></pre></div>
<p>We then use <code>left_join</code> to merge the predictions from the <code>cv_only</code> (computer vision) data set onto the records from the <code>hv_only</code> (human vision) data set.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb55-1" data-line-number="1">hv_mismatch &lt;-<span class="st"> </span>hv_only <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb55-2" data-line-number="2"><span class="st">  </span><span class="kw">left_join</span>(cv_only, <span class="dt">by =</span> <span class="st">&quot;filename&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb55-3" data-line-number="3"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">multiple_det_cv =</span> multiple_det) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb55-4" data-line-number="4"><span class="st">  </span><span class="kw">select</span>(filename, value, class_cv, class_hv, multiple_det_cv, multiple_det_hv)</a></code></pre></div>
<p>We then check for any computer vision records that are not yet accounted for in our data sets containing records with correct or incorrect predictions, i.e., <code>matched</code> and <code>hv_mismatch</code>, respectively.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" data-line-number="1">cv_others &lt;-<span class="st"> </span>cv_only[cv_only<span class="op">$</span>filename <span class="op">%in%</span><span class="st"> </span>matched<span class="op">$</span>filename <span class="op">!=</span><span class="st"> </span><span class="ot">TRUE</span>,]</a>
<a class="sourceLine" id="cb56-2" data-line-number="2">cv_others &lt;-<span class="st"> </span>cv_only[cv_only<span class="op">$</span>filename <span class="op">%in%</span><span class="st"> </span>hv_mismatch<span class="op">$</span>filename <span class="op">!=</span><span class="st"> </span><span class="ot">TRUE</span>,]</a>
<a class="sourceLine" id="cb56-3" data-line-number="3"></a>
<a class="sourceLine" id="cb56-4" data-line-number="4"><span class="kw">table</span>(cv_others<span class="op">$</span>multiple_det)</a></code></pre></div>
<pre><code>## &lt; table of extent 0 &gt;</code></pre>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb58-1" data-line-number="1"><span class="kw">table</span>(cv_others<span class="op">$</span>multiple_det)</a></code></pre></div>
<pre><code>## &lt; table of extent 0 &gt;</code></pre>
<p>Then, we select only the variables we need, combine the matched and mismatched data sets, and again make sure that the classifications have the same factor levels attribute.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb60-1" data-line-number="1">matched &lt;-<span class="st"> </span>matched <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb60-2" data-line-number="2"><span class="st">  </span><span class="kw">select</span>(filename, value, class_cv, class_hv)</a>
<a class="sourceLine" id="cb60-3" data-line-number="3">hv_mismatch &lt;-<span class="st"> </span>hv_mismatch <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb60-4" data-line-number="4"><span class="st">  </span><span class="kw">select</span>(filename, value, class_cv, class_hv)</a>
<a class="sourceLine" id="cb60-5" data-line-number="5"></a>
<a class="sourceLine" id="cb60-6" data-line-number="6">both_visions &lt;-<span class="st"> </span><span class="kw">rbind</span>(matched, hv_mismatch)</a>
<a class="sourceLine" id="cb60-7" data-line-number="7">both_visions<span class="op">$</span>class_cv &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">as.character</span>(both_visions<span class="op">$</span>class_cv), <span class="dt">levels =</span> all_levels)</a>
<a class="sourceLine" id="cb60-8" data-line-number="8">both_visions<span class="op">$</span>class_hv &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">as.character</span>(both_visions<span class="op">$</span>class_hv), <span class="dt">levels =</span> all_levels)</a></code></pre></div>
</div>
<div id="confusion-matrix-and-performance-measures-1" class="section level3">
<h3><span class="header-section-number">4.6.5</span> Confusion matrix and performance measures</h3>
<p>Finally, we can proceed with estimating a confusion matrix and various AI performance measures using the <code>confusionMatrix</code> function from the <code>caret</code> package <span class="citation">(Kuhn <a href="#ref-R-caret">2021</a>)</span> and specifying a 0.65 confidence threshold to accept MD predictions. We can then plot the confusion matrix using <code>ggplot2</code> <span class="citation">(Wickham et al. <a href="#ref-R-ggplot2">2018</a>)</span>. The <code>confusionMatrix</code> function requires a data argument for predicted classes and a reference for true classifications, both as factor classes and with the same factor levels. We specify <code>mode = &quot;prec_recall&quot;</code> when calling the <code>confusionMatrix</code> function <span class="citation">(Kuhn <a href="#ref-R-caret">2021</a>)</span> to generate estimates of precision and recall.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb61-1" data-line-number="1"><span class="kw">library</span>(caret) <span class="co"># to inspect model performance</span></a>
<a class="sourceLine" id="cb61-2" data-line-number="2"><span class="kw">library</span>(ggplot2)</a>
<a class="sourceLine" id="cb61-3" data-line-number="3"></a>
<a class="sourceLine" id="cb61-4" data-line-number="4"><span class="co"># Estimate confusion matrix</span></a>
<a class="sourceLine" id="cb61-5" data-line-number="5">both_visions_<span class="fl">0.65</span> &lt;-<span class="st"> </span>both_visions</a>
<a class="sourceLine" id="cb61-6" data-line-number="6">both_visions_<span class="fl">0.65</span><span class="op">$</span>class_cv[both_visions_<span class="fl">0.65</span><span class="op">$</span>value <span class="op">&lt;</span><span class="st"> </span><span class="fl">0.65</span>] &lt;-<span class="st"> &quot;Blank&quot;</span>  </a>
<a class="sourceLine" id="cb61-7" data-line-number="7">cm_md_<span class="fl">0.65</span> &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(<span class="dt">data =</span> both_visions_<span class="fl">0.65</span><span class="op">$</span>class_cv, </a>
<a class="sourceLine" id="cb61-8" data-line-number="8">                      <span class="dt">reference =</span> both_visions_<span class="fl">0.65</span><span class="op">$</span>class_hv, </a>
<a class="sourceLine" id="cb61-9" data-line-number="9">                      <span class="dt">mode =</span> <span class="st">&quot;prec_recall&quot;</span>)</a>
<a class="sourceLine" id="cb61-10" data-line-number="10"></a>
<a class="sourceLine" id="cb61-11" data-line-number="11"><span class="co"># Plot confusion matrix</span></a>
<a class="sourceLine" id="cb61-12" data-line-number="12">plot_cm_md_<span class="fl">0.65</span> &lt;-<span class="st"> </span>cm_md_<span class="fl">0.65</span> <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb61-13" data-line-number="13"><span class="st">  </span><span class="kw">pluck</span>(<span class="st">&quot;table&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb61-14" data-line-number="14"><span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb61-15" data-line-number="15"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">Frequency =</span> Freq) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb61-16" data-line-number="16"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">y=</span>Prediction, <span class="dt">x=</span>Reference, <span class="dt">fill=</span>Frequency)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb61-17" data-line-number="17"><span class="st">  </span><span class="kw">geom_raster</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb61-18" data-line-number="18"><span class="st">  </span><span class="kw">scale_fill_gradient</span>(<span class="dt">low =</span> <span class="st">&quot;#D6EAF8&quot;</span>,<span class="dt">high =</span> <span class="st">&quot;#2E86C1&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb61-19" data-line-number="19"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">90</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb61-20" data-line-number="20"><span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> Frequency), <span class="dt">size =</span> <span class="dv">3</span>) <span class="co">#set size to 3</span></a>
<a class="sourceLine" id="cb61-21" data-line-number="21"></a>
<a class="sourceLine" id="cb61-22" data-line-number="22">plot_cm_md_<span class="fl">0.65</span></a></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:confmatrix-md"></span>
<img src="03-md_files/figure-html/confmatrix-md-1.png" alt="Confusion matrix applied to classifications from MegaDetector using a confidence threshold of 0.65." width="672" />
<p class="caption">
Figure 4.6: Confusion matrix applied to classifications from MegaDetector using a confidence threshold of 0.65.
</p>
</div>
<p>Now we can use the confusion matrix to estimate metrics of model performance including accuracy, precision, recall and F1 score (See Chapter <a href="introduction.html#introduction">1</a> for metrics description).</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb62-1" data-line-number="1">(overall_accuracy &lt;-<span class="st"> </span>cm_md_<span class="fl">0.65</span> <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb62-2" data-line-number="2"><span class="st">  </span><span class="kw">pluck</span>(<span class="st">&quot;overall&quot;</span>, <span class="st">&quot;Accuracy&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb62-3" data-line-number="3"><span class="st">  </span><span class="kw">round</span>(., <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## [1] 0.93</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb64-1" data-line-number="1">classes_metrics_md_<span class="fl">0.65</span>  &lt;-<span class="st"> </span>cm_md_<span class="fl">0.65</span> <span class="op">%&gt;%</span><span class="st">   </span></a>
<a class="sourceLine" id="cb64-2" data-line-number="2"><span class="st">  </span><span class="kw">pluck</span>(<span class="st">&quot;byClass&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb64-3" data-line-number="3"><span class="st">  </span><span class="kw">t</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb64-4" data-line-number="4"><span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb64-5" data-line-number="5"><span class="st">  </span><span class="kw">select</span>(Precision, Recall, F1) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb64-6" data-line-number="6"><span class="st">  </span><span class="kw">mutate</span>(<span class="kw">across</span>(<span class="kw">where</span>(is.numeric), <span class="op">~</span><span class="kw">round</span>(., <span class="dv">2</span>))) </a>
<a class="sourceLine" id="cb64-7" data-line-number="7"></a>
<a class="sourceLine" id="cb64-8" data-line-number="8">classes_metrics_md_<span class="fl">0.65</span> &lt;-<span class="st"> </span>classes_metrics_md_<span class="fl">0.65</span> <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb64-9" data-line-number="9"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Class =</span> <span class="st">&quot;Animal&quot;</span>, <span class="dt">.before =</span> Precision)</a></code></pre></div>
<div id="htmlwidget-f41ffd6f4a69a36b2fb4" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-f41ffd6f4a69a36b2fb4">{"x":{"filter":"none","vertical":false,"data":[["1"],["Animal"],[0.98],[0.93],[0.96]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Class<\/th>\n      <th>Precision<\/th>\n      <th>Recall<\/th>\n      <th>F1<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[2,3,4]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<table>
<caption>
<span id="tab:myDThtmltools2">Table 4.1: </span>Model performance metrics for the detection of animals in images using MegaDetector and a 0.65 confidence threshold.
</caption>
</table>
<p>We see that the model is really good at picking up animals, with a precision of 98% at a 93% recall. Thus, we expect that 93% of the animals present in our images will be picked up by MD. Further, only 2% of the images flagged as having an animal will not. We can also inspect model performance for a range of confidence thresholds as we demonstrate in the next section.</p>
</div>
<div id="md-thresholds" class="section level3">
<h3><span class="header-section-number">4.6.6</span> Confidence thresholds</h3>
<p>Lets begin by looking at the confidence values associated with each MD classification using the <code>geom_bar</code> function <span class="citation">(Wickham et al. <a href="#ref-R-ggplot2">2018</a>)</span>. Before plotting, we filter the <code>both_visions</code> data frame to remove blanks as they do not have associated confidence values.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb65-1" data-line-number="1"><span class="co"># Plot confidence values </span></a>
<a class="sourceLine" id="cb65-2" data-line-number="2">both_visions <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb65-3" data-line-number="3"><span class="st">  </span><span class="kw">filter</span>(class_cv <span class="op">!=</span><span class="st"> &quot;Blank&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb65-4" data-line-number="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(value, <span class="dt">group =</span> class_cv, <span class="dt">colour =</span> class_cv)) <span class="op">+</span></a>
<a class="sourceLine" id="cb65-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_bar</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb65-6" data-line-number="6"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>class_cv, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb65-7" data-line-number="7"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Empirical distribution&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;Confidence values&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb65-8" data-line-number="8"><span class="st">  </span><span class="kw">scale_color_viridis_d</span>()</a></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-12"></span>
<img src="03-md_files/figure-html/unnamed-chunk-12-1.png" alt="Distribution of confidence values for animals predicted by MegaDetector." width="864" />
<p class="caption">
Figure 4.7: Distribution of confidence values for animals predicted by MegaDetector.
</p>
</div>
<p>We see that the distribution of confidence values for “Animal” classifications is left skewed with most records having high confidence values suggesting that the AI prediction is presumed to be correct most of the time.</p>
<p>To inspect how precision and recall change when different confidence thresholds are established for assigning a class predicted by computer vision, we define a function that will calculate these metrics for a user-defined confidence threshold. This function will assign a “Blank” label whenever the confidence for a computer vision prediction is below a particular confidence threshold. Higher thresholds should reduce the number of false positives but at the expense of more false negatives. We then estimate the same performance metrics for the specified confidence threshold. By repeating this process for several different thresholds, users can evaluate how precision and recall change with the confidence threshold and choose a threshold that balances these two performance metrics.</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb66-1" data-line-number="1">threshold_for_metrics &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">conf_threshold =</span> <span class="fl">0.7</span>) {</a>
<a class="sourceLine" id="cb66-2" data-line-number="2">  tmp &lt;-<span class="st"> </span>both_visions</a>
<a class="sourceLine" id="cb66-3" data-line-number="3">  tmp<span class="op">$</span>class_cv[tmp<span class="op">$</span>value <span class="op">&lt;</span><span class="st"> </span>conf_threshold] &lt;-<span class="st"> &quot;Blank&quot;</span> </a>
<a class="sourceLine" id="cb66-4" data-line-number="4"></a>
<a class="sourceLine" id="cb66-5" data-line-number="5">  cm &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(<span class="dt">data =</span> tmp<span class="op">$</span>class_cv, </a>
<a class="sourceLine" id="cb66-6" data-line-number="6">                        <span class="dt">reference =</span> tmp<span class="op">$</span>class_hv, </a>
<a class="sourceLine" id="cb66-7" data-line-number="7">                        <span class="dt">mode =</span> <span class="st">&quot;prec_recall&quot;</span>) </a>
<a class="sourceLine" id="cb66-8" data-line-number="8"></a>
<a class="sourceLine" id="cb66-9" data-line-number="9">  classes_metrics &lt;-<span class="st"> </span>cm <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># get confusion matrix</span></a>
<a class="sourceLine" id="cb66-10" data-line-number="10"><span class="st">    </span><span class="kw">pluck</span>(<span class="st">&quot;byClass&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># get metrics by class</span></a>
<a class="sourceLine" id="cb66-11" data-line-number="11"><span class="st">    </span><span class="kw">t</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb66-12" data-line-number="12"><span class="st">    </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb66-13" data-line-number="13"><span class="st">    </span><span class="kw">select</span>(Precision, Recall, F1) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb66-14" data-line-number="14"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">conf_threshold =</span> conf_threshold)</a>
<a class="sourceLine" id="cb66-15" data-line-number="15">  </a>
<a class="sourceLine" id="cb66-16" data-line-number="16">  <span class="kw">return</span>(classes_metrics) <span class="co"># return a data frame with metrics for every class</span></a>
<a class="sourceLine" id="cb66-17" data-line-number="17">}</a></code></pre></div>
<p>Let’s estimate model performance metrics for confidence values ranging from 0.1 to 0.99 using the map_df function <span class="citation">(Henry and Wickham <a href="#ref-purrr">2020</a>)</span> . The map_df function <span class="citation">(Henry and Wickham <a href="#ref-purrr">2020</a>)</span> returns a data frame object. Once we get a data frame of model performance metrics for a range of confidence values, we can plot the results using the <code>ggplot2</code> package <span class="citation">(Wickham et al. <a href="#ref-R-ggplot2">2018</a>)</span>.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb67-1" data-line-number="1">conf_vector =<span class="st"> </span><span class="kw">seq</span>(<span class="fl">0.1</span>, <span class="fl">0.99</span>, <span class="dt">length=</span><span class="dv">100</span>)</a>
<a class="sourceLine" id="cb67-2" data-line-number="2"></a>
<a class="sourceLine" id="cb67-3" data-line-number="3">metrics_all_confs &lt;-<span class="st"> </span><span class="kw">map_df</span>(conf_vector, threshold_for_metrics)</a></code></pre></div>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb68-1" data-line-number="1">prec_rec_md &lt;-<span class="st"> </span>metrics_all_confs <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb68-2" data-line-number="2"><span class="st">  </span><span class="kw">rename</span>(<span class="st">`</span><span class="dt">Confidence threshold</span><span class="st">`</span> =<span class="st"> </span>conf_threshold) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb68-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Recall, <span class="dt">y =</span> Precision)) <span class="op">+</span></a>
<a class="sourceLine" id="cb68-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">size =</span> <span class="st">`</span><span class="dt">Confidence threshold</span><span class="st">`</span>, <span class="dt">color =</span> <span class="st">&quot;#440154FF&quot;</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb68-5" data-line-number="5"><span class="st">  </span><span class="kw">scale_size</span>(<span class="dt">range =</span> <span class="kw">c</span>(<span class="fl">0.1</span>,<span class="dv">3</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb68-6" data-line-number="6"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Recall&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Precision&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb68-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color =</span> <span class="st">&quot;#440154FF&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb68-8" data-line-number="8"><span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="st">&quot;#440154FF&quot;</span>, <span class="dt">name =</span> <span class="st">&quot;Class&quot;</span>, <span class="dt">labels =</span> <span class="st">&quot;Animal&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb68-9" data-line-number="9"><span class="st">  </span><span class="kw">xlim</span>(<span class="dv">0</span>, <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylim</span>(<span class="dv">0</span>, <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb68-10" data-line-number="10"></a>
<a class="sourceLine" id="cb68-11" data-line-number="11"></a>
<a class="sourceLine" id="cb68-12" data-line-number="12">prec_rec_md</a></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:md-thresholds"></span>
<img src="03-md_files/figure-html/md-thresholds-1.png" alt="Precision and recall for different confidence thresholds for the animal class predicted by MegaDetector." width="864" />
<p class="caption">
Figure 4.8: Precision and recall for different confidence thresholds for the animal class predicted by MegaDetector.
</p>
</div>
<p>We see that as we increase the confidence threshold, precision increases and recall decreases for the “Animal” class (Figure <a href="megadetector.html#fig:md-thresholds">4.8</a>). Ideally, we would like to choose a confidence threshold that maximizes both precision and recall, though the latter is likely to be more important in most cases. Remember that precision tells us the probability that the class is truly present when AI identifies the class as being present in an image (Chapter <a href="introduction.html#introduction">1</a>). If AI suffers from low precision, then we may have to manually review photos that AI tags as having a class present in order to remove false positives. Recall, on the other hand, tells us how likely AI is to find a class in the image when it is truly present. If AI suffers from low recall, then it will miss many photos containing a class that is truly present. To remedy this problem, we would need to review images where AI says the class is absent in order to reduce false negatives.</p>
<p>Let’s say that we were willing to miss only 3% of the animals present. In this case, we could pick the confidence threshold that maximizes precision under the constraint that recall does not fall below 97%.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb69-1" data-line-number="1">conf_meets &lt;-<span class="st"> </span>metrics_all_confs <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb69-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="kw">across</span>(<span class="kw">where</span>(is.numeric), <span class="op">~</span><span class="kw">round</span>(., <span class="dv">2</span>))) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb69-3" data-line-number="3"><span class="st">  </span><span class="kw">filter</span>(Recall <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.97</span>)</a></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-16">Table 4.2: </span>Performance metrics using a confidence threshold that
maximizes precision for a 97% recall.</caption>
<thead>
<tr class="header">
<th align="right">Precision</th>
<th align="right">Recall</th>
<th align="right">F1</th>
<th align="right">conf_threshold</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.95</td>
<td align="right">0.97</td>
<td align="right">0.96</td>
<td align="right">0.1</td>
</tr>
</tbody>
</table>
<p>We see that we can obtain a precision to 95% (while keeping recall = 97%) by using a confidence threshold of 0.1.
Thus, if we integrate MD output with Timelapse, filtering using a confidence threshold of 0.1, we expect to capture 97% of Animals that are truly present and 95% of the flagged images should actually include one or more animals.</p>
<p>Let’s examine the confusion matrix using this threshold.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb70-1" data-line-number="1">threshold &lt;-<span class="st"> </span>conf_meets[<span class="kw">which.max</span>(conf_meets<span class="op">$</span>Precision), <span class="dv">4</span>]</a>
<a class="sourceLine" id="cb70-2" data-line-number="2">  </a>
<a class="sourceLine" id="cb70-3" data-line-number="3">conf_red &lt;-<span class="st"> </span>both_visions</a>
<a class="sourceLine" id="cb70-4" data-line-number="4">conf_red<span class="op">$</span>class_cv[conf_red<span class="op">$</span>value <span class="op">&lt;</span><span class="st"> </span>threshold] &lt;-<span class="st"> &quot;Blank&quot;</span>  </a>
<a class="sourceLine" id="cb70-5" data-line-number="5"></a>
<a class="sourceLine" id="cb70-6" data-line-number="6">  </a>
<a class="sourceLine" id="cb70-7" data-line-number="7">cm_md_th &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(<span class="dt">data =</span> conf_red<span class="op">$</span>class_cv, </a>
<a class="sourceLine" id="cb70-8" data-line-number="8">                        <span class="dt">reference =</span> conf_red<span class="op">$</span>class_hv, </a>
<a class="sourceLine" id="cb70-9" data-line-number="9">                        <span class="dt">mode =</span> <span class="st">&quot;prec_recall&quot;</span>)</a>
<a class="sourceLine" id="cb70-10" data-line-number="10"></a>
<a class="sourceLine" id="cb70-11" data-line-number="11">plot_cm_md_th &lt;-<span class="st"> </span>cm_md_th <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb70-12" data-line-number="12"><span class="st">        </span><span class="kw">pluck</span>(<span class="st">&quot;table&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb70-13" data-line-number="13"><span class="st">        </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb70-14" data-line-number="14"><span class="st">        </span><span class="kw">rename</span>(<span class="dt">Frequency =</span> Freq) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb70-15" data-line-number="15"><span class="st">        </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">y=</span>Prediction, <span class="dt">x=</span>Reference, <span class="dt">fill=</span>Frequency)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb70-16" data-line-number="16"><span class="st">  </span><span class="kw">geom_raster</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb70-17" data-line-number="17"><span class="st">  </span><span class="kw">scale_fill_gradient</span>(<span class="dt">low =</span> <span class="st">&quot;#D6EAF8&quot;</span>,<span class="dt">high =</span> <span class="st">&quot;#2E86C1&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb70-18" data-line-number="18"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">90</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb70-19" data-line-number="19"><span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> Frequency), <span class="dt">size =</span> <span class="dv">3</span>)</a></code></pre></div>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" data-line-number="1"><span class="kw">library</span>(patchwork)</a>
<a class="sourceLine" id="cb71-2" data-line-number="2"></a>
<a class="sourceLine" id="cb71-3" data-line-number="3">plot_cm_md_<span class="fl">0.65</span> &lt;-<span class="st"> </span>plot_cm_md_<span class="fl">0.65</span> <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;None&quot;</span>)</a>
<a class="sourceLine" id="cb71-4" data-line-number="4">plot_cm_md_th &lt;-<span class="st"> </span>plot_cm_md_th <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;None&quot;</span>)</a>
<a class="sourceLine" id="cb71-5" data-line-number="5"></a>
<a class="sourceLine" id="cb71-6" data-line-number="6">(plots_cms_md &lt;-<span class="st"> </span>plot_cm_md_<span class="fl">0.65</span> <span class="op">+</span></a>
<a class="sourceLine" id="cb71-7" data-line-number="7"><span class="st">  </span>plot_cm_md_th <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb71-8" data-line-number="8"><span class="st">  </span><span class="kw">plot_annotation</span>(<span class="dt">tag_levels =</span> <span class="st">&#39;A&#39;</span>))</a></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:compare"></span>
<img src="03-md_files/figure-html/compare-1.png" alt="Confusion matrices applied to classifications from MegaDetector using a confidence threshold of 0.65 (A) and 0.1 (B)." width="100%" />
<p class="caption">
Figure 4.9: Confusion matrices applied to classifications from MegaDetector using a confidence threshold of 0.65 (A) and 0.1 (B).
</p>
</div>
<p>Comparing the confusion matrix with our original (using a 0.65 confidence threshold; Figure <a href="megadetector.html#fig:compare">4.9</a>), we see that we have decreased the false negatives using a confidence threshold of 0.1 (i.e., cases where MD suggests a blank image but an animal is present; last row, first column) but increased the number of false positives (i.e., cases where MD suggests an animal is present, but the image is blank; first row, second column).</p>
</div>
</div>
<div id="conclusions-1" class="section level2">
<h2><span class="header-section-number">4.7</span> Conclusions</h2>
<p>We have seen how to use MD and how to integrate its output with Timelapse for using AI while processing camera trap data. Additionally, we illustrated how to evaluate MD performance by comparing true classifications with computer predictions. We found that MD has a high performance to detect animals in images. Thus, the human labor required to review photos can be reliably focused on images with the “Animal” class predictions.</p>
<p>We also showed how users can explore MD performance by comparing confusion matrices estimated using different confidence thresholds. This comparison will be useful to understand the trade-off between precision and recall, and help users choose a confidence threshold that maximizes these metrics using their particular data sets.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-magrittr">
<p>Bache, Stefan Milton, and Hadley Wickham. 2020. <em>Magrittr: A Forward-Pipe Operator for R</em>. <a href="https://CRAN.R-project.org/package=magrittr">https://CRAN.R-project.org/package=magrittr</a>.</p>
</div>
<div id="ref-beery2019efficient">
<p>Beery, Sara, Dan Morris, and Siyu Yang. 2019. “Efficient Pipeline for Camera Trap Image Review.” <em>arXiv Preprint arXiv:1907.06772</em>.</p>
</div>
<div id="ref-greenberg-timelapse">
<p>Greenberg, Saul. 2020. “Timelapse 2.0 User Guide.” Computer Program. Greenberg Consulting Inc. / University of Calgary.</p>
</div>
<div id="ref-greenberg-design">
<p>Greenberg, Saul, Theresa Godin, and Jesse Whittington. 2019. “Design Patterns for Wildlife-Related Camera Trap Image Analysis.” Journal Article. <em>Ecology and Evolution</em> 9 (24): 13706–30. <a href="https://doi.org/10.1002/ece3.5767">https://doi.org/10.1002/ece3.5767</a>.</p>
</div>
<div id="ref-purrr">
<p>Henry, Lionel, and Hadley Wickham. 2020. <em>Purrr: Functional Programming Tools</em>. <a href="https://CRAN.R-project.org/package=purrr">https://CRAN.R-project.org/package=purrr</a>.</p>
</div>
<div id="ref-R-caret">
<p>Kuhn, Max. 2021. <em>Caret: Classification and Regression Training</em>. <a href="https://CRAN.R-project.org/package=caret">https://CRAN.R-project.org/package=caret</a>.</p>
</div>
<div id="ref-here">
<p>Müller, Kirill. 2017. <em>Here: A Simpler Way to Find Your Files</em>. <a href="https://CRAN.R-project.org/package=here">https://CRAN.R-project.org/package=here</a>.</p>
</div>
<div id="ref-R-base">
<p>R Core Team. 2021. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.</p>
</div>
<div id="ref-R-ggplot2">
<p>Wickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, and Kara Woo. 2018. <em>Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics</em>. <a href="https://CRAN.R-project.org/package=ggplot2">https://CRAN.R-project.org/package=ggplot2</a>.</p>
</div>
<div id="ref-R-dplyr">
<p>Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2019. <em>Dplyr: A Grammar of Data Manipulation</em>. <a href="https://CRAN.R-project.org/package=dplyr">https://CRAN.R-project.org/package=dplyr</a>.</p>
</div>
<div id="ref-R-tidyr">
<p>Wickham, Hadley, and Lionel Henry. 2018. <em>Tidyr: Easily Tidy Data with ’Spread()’ and ’Gather()’ Functions</em>. <a href="https://CRAN.R-project.org/package=tidyr">https://CRAN.R-project.org/package=tidyr</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="wildlife-insights.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mlwic2-machine-learning-for-wildlife-image-classification.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03-md.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["CTWorkflows.pdf", "CTWorkflows.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
