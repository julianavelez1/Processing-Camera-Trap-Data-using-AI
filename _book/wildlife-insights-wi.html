<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Wildlife Insights (WI) | Guide for using artificial intelligence systems for camera trap data processing</title>
  <meta name="description" content="We aim to provide an overview of the steps required to use platforms that implement artificial intelligence into workflows for processing camera trap images." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Wildlife Insights (WI) | Guide for using artificial intelligence systems for camera trap data processing" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="We aim to provide an overview of the steps required to use platforms that implement artificial intelligence into workflows for processing camera trap images." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Wildlife Insights (WI) | Guide for using artificial intelligence systems for camera trap data processing" />
  
  <meta name="twitter:description" content="We aim to provide an overview of the steps required to use platforms that implement artificial intelligence into workflows for processing camera trap images." />
  

<meta name="author" content="Juliana Velez and John Fieberg" />


<meta name="date" content="2022-02-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="camera-trap-data.html"/>
<link rel="next" href="megadetector---microsoft-ai.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.19/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">Guide for using artificial intelligence systems for camera trap data processing</a></li>

<li class="divider"></li>
<li><a href="index.html#section"></a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="camera-trap-data.html"><a href="camera-trap-data.html"><i class="fa fa-check"></i><b>2</b> Camera-trap data</a></li>
<li class="chapter" data-level="3" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html"><i class="fa fa-check"></i><b>3</b> Wildlife Insights (WI)</a><ul>
<li class="chapter" data-level="3.1" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html#set-up"><i class="fa fa-check"></i><b>3.1</b> Set-up</a></li>
<li class="chapter" data-level="3.2" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html#uploadformat-data"><i class="fa fa-check"></i><b>3.2</b> Upload/format data</a></li>
<li class="chapter" data-level="3.3" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html#uploadenter-metadata"><i class="fa fa-check"></i><b>3.3</b> Upload/enter metadata</a></li>
<li class="chapter" data-level="3.4" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html#processing-images---ai-module"><i class="fa fa-check"></i><b>3.4</b> Processing images - AI module</a></li>
<li class="chapter" data-level="3.5" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html#post-ai-image-processing"><i class="fa fa-check"></i><b>3.5</b> Post-AI image processing</a></li>
<li class="chapter" data-level="3.6" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html#wi-output"><i class="fa fa-check"></i><b>3.6</b> Using AI output</a></li>
<li class="chapter" data-level="3.7" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html#wi-performance"><i class="fa fa-check"></i><b>3.7</b> Assessing AI performance</a><ul>
<li class="chapter" data-level="3.7.1" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html#reading-in-data-introduction-to-the-purrr-package"><i class="fa fa-check"></i><b>3.7.1</b> Reading in data, introduction to the Purrr package</a></li>
<li class="chapter" data-level="3.7.2" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html#removing-duplicate-images"><i class="fa fa-check"></i><b>3.7.2</b> Removing duplicate images</a></li>
<li class="chapter" data-level="3.7.3" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html#images-with-multiple-observations-of-the-same-species"><i class="fa fa-check"></i><b>3.7.3</b> Images with multiple observations of the same species</a></li>
<li class="chapter" data-level="3.7.4" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html#images-with-multiple-species"><i class="fa fa-check"></i><b>3.7.4</b> Images with multiple species</a></li>
<li class="chapter" data-level="3.7.5" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html#summarizing-human-and-computer-vision-records-by-species"><i class="fa fa-check"></i><b>3.7.5</b> Summarizing human and computer vision records by species</a></li>
<li class="chapter" data-level="3.7.6" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html#confusion-matrix-and-performance-measures"><i class="fa fa-check"></i><b>3.7.6</b> Confusion matrix and performance measures</a></li>
<li class="chapter" data-level="3.7.7" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html#confidence-thresholds"><i class="fa fa-check"></i><b>3.7.7</b> Confidence thresholds</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="wildlife-insights-wi.html"><a href="wildlife-insights-wi.html#conclusions"><i class="fa fa-check"></i><b>3.8</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="megadetector---microsoft-ai.html"><a href="megadetector---microsoft-ai.html"><i class="fa fa-check"></i><b>4</b> MegaDetector - Microsoft AI</a><ul>
<li class="chapter" data-level="4.1" data-path="megadetector---microsoft-ai.html"><a href="megadetector---microsoft-ai.html#md-upload"><i class="fa fa-check"></i><b>4.1</b> Upload/format data</a></li>
<li class="chapter" data-level="4.2" data-path="megadetector---microsoft-ai.html"><a href="megadetector---microsoft-ai.html#md-metadata"><i class="fa fa-check"></i><b>4.2</b> Upload/enter metadata</a></li>
<li class="chapter" data-level="4.3" data-path="megadetector---microsoft-ai.html"><a href="megadetector---microsoft-ai.html#md-process"><i class="fa fa-check"></i><b>4.3</b> Process images - AI module</a></li>
<li class="chapter" data-level="4.4" data-path="megadetector---microsoft-ai.html"><a href="megadetector---microsoft-ai.html#md-timelapse"><i class="fa fa-check"></i><b>4.4</b> Image processing with Timelapse 2</a></li>
<li class="chapter" data-level="4.5" data-path="megadetector---microsoft-ai.html"><a href="megadetector---microsoft-ai.html#md-output"><i class="fa fa-check"></i><b>4.5</b> Using AI output</a></li>
<li class="chapter" data-level="4.6" data-path="megadetector---microsoft-ai.html"><a href="megadetector---microsoft-ai.html#md-performance"><i class="fa fa-check"></i><b>4.6</b> Assessing AI performance</a><ul>
<li class="chapter" data-level="4.6.1" data-path="megadetector---microsoft-ai.html"><a href="megadetector---microsoft-ai.html#reading-in-data-introduction-to-the-purrr-package-1"><i class="fa fa-check"></i><b>4.6.1</b> Reading in data, introduction to the Purrr package</a></li>
<li class="chapter" data-level="4.6.2" data-path="megadetector---microsoft-ai.html"><a href="megadetector---microsoft-ai.html#format-computer-vision-data-set"><i class="fa fa-check"></i><b>4.6.2</b> Format computer vision data set</a></li>
<li class="chapter" data-level="4.6.3" data-path="megadetector---microsoft-ai.html"><a href="megadetector---microsoft-ai.html#md-format-hv"><i class="fa fa-check"></i><b>4.6.3</b> Format human vision data set</a></li>
<li class="chapter" data-level="4.6.4" data-path="megadetector---microsoft-ai.html"><a href="megadetector---microsoft-ai.html#merging-computer-and-human-vision-data-sets"><i class="fa fa-check"></i><b>4.6.4</b> Merging computer and human vision data sets</a></li>
<li class="chapter" data-level="4.6.5" data-path="megadetector---microsoft-ai.html"><a href="megadetector---microsoft-ai.html#confusion-matrix-and-performance-measures-1"><i class="fa fa-check"></i><b>4.6.5</b> Confusion matrix and performance measures</a></li>
<li class="chapter" data-level="4.6.6" data-path="megadetector---microsoft-ai.html"><a href="megadetector---microsoft-ai.html#md-thresholds"><i class="fa fa-check"></i><b>4.6.6</b> Confidence thresholds</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="megadetector---microsoft-ai.html"><a href="megadetector---microsoft-ai.html#conclusions-1"><i class="fa fa-check"></i><b>4.7</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html"><i class="fa fa-check"></i><b>5</b> MLWIC2: Machine Learning for Wildlife Image Classification</a><ul>
<li class="chapter" data-level="5.1" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#set-up-1"><i class="fa fa-check"></i><b>5.1</b> Set-up</a></li>
<li class="chapter" data-level="5.2" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#format-mlwic2"><i class="fa fa-check"></i><b>5.2</b> Upload/format data</a></li>
<li class="chapter" data-level="5.3" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#mlwic2-ai-module"><i class="fa fa-check"></i><b>5.3</b> Process images - AI module</a></li>
<li class="chapter" data-level="5.4" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#ai-mlwic2"><i class="fa fa-check"></i><b>5.4</b> Assessing AI performance</a><ul>
<li class="chapter" data-level="5.4.1" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#format-human-vision-data-set"><i class="fa fa-check"></i><b>5.4.1</b> Format human vision data set</a></li>
<li class="chapter" data-level="5.4.2" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#format-computer-vision-data-set-1"><i class="fa fa-check"></i><b>5.4.2</b> Format computer vision data set</a></li>
<li class="chapter" data-level="5.4.3" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#merging-computer-and-human-vision-data-sets-1"><i class="fa fa-check"></i><b>5.4.3</b> Merging computer and human vision data sets</a></li>
<li class="chapter" data-level="5.4.4" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#summarizing-human-and-computer-vision-records-by-class"><i class="fa fa-check"></i><b>5.4.4</b> Summarizing human and computer vision records by class</a></li>
<li class="chapter" data-level="5.4.5" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#confusion-matrix-and-performance-measures-2"><i class="fa fa-check"></i><b>5.4.5</b> Confusion matrix and performance measures</a></li>
<li class="chapter" data-level="5.4.6" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#confidence-thresholds-1"><i class="fa fa-check"></i><b>5.4.6</b> Confidence thresholds</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#model-training"><i class="fa fa-check"></i><b>5.5</b> Model training</a></li>
<li class="chapter" data-level="5.6" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#classify-trained"><i class="fa fa-check"></i><b>5.6</b> Classify using a trained model</a></li>
<li class="chapter" data-level="5.7" data-path="mlwic2-machine-learning-for-wildlife-image-classification.html"><a href="mlwic2-machine-learning-for-wildlife-image-classification.html#conclusion"><i class="fa fa-check"></i><b>5.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="conservation-ai.html"><a href="conservation-ai.html"><i class="fa fa-check"></i><b>6</b> Conservation AI</a><ul>
<li class="chapter" data-level="6.1" data-path="conservation-ai.html"><a href="conservation-ai.html#set-up-2"><i class="fa fa-check"></i><b>6.1</b> Set-up</a></li>
<li class="chapter" data-level="6.2" data-path="conservation-ai.html"><a href="conservation-ai.html#uploadformat-data-1"><i class="fa fa-check"></i><b>6.2</b> Upload/format data</a></li>
<li class="chapter" data-level="6.3" data-path="conservation-ai.html"><a href="conservation-ai.html#image-tagging"><i class="fa fa-check"></i><b>6.3</b> Image tagging</a></li>
<li class="chapter" data-level="6.4" data-path="conservation-ai.html"><a href="conservation-ai.html#process-images---ai-module"><i class="fa fa-check"></i><b>6.4</b> Process images - AI module</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Guide for using artificial intelligence systems for camera trap data processing</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="wildlife-insights-wi" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Wildlife Insights (WI)</h1>
<p>Wildlife Insights (WI) is an initiative developed by Conservation International in partnership with the Wildlife Conservation Society, World Wildlife Fund, Zoological Society of London, The Smithsonian Institution, North Carolina Museum of Natural Sciences, Yale University and Google <span class="citation">(Ahumada et al. <a href="#ref-ahumada_wi">2019</a>)</span>. WI provides an interface and tools to support workflows for processing, visualizing, and analyzing camera trap data. These tools include infrastructure to store, review and process images, AI to classify species and blanks, and an analysis engine for implementing common statistical methods with camera trap data (e.g., estimation of species’ activity patterns, occupancy, density and diversity indices) <span class="citation">(Ahumada et al. <a href="#ref-ahumada_wi">2019</a>)</span>. Beyond serving as an interface for image processing and data analysis, WI was also conceived as a data repository for hosting camera trap data collected worldwide; images and associated metadata stored in WI can be downloaded by the public after sensitive content (e.g., images with people or endangered species) has been removed and once an embargo time (maximum 48 months) provided by data providers has passed <span class="citation">(Ahumada et al. <a href="#ref-ahumada_wi">2019</a>)</span>.</p>
<p>WI provides comprehensive guides for navigating the platform and tutorials showing step-by-step usage of the system’s features. This documentation can be found here: <a href="https://www.wildlifeinsights.org/get-started" class="uri">https://www.wildlifeinsights.org/get-started</a>.</p>
<p>Additionally, WI provides references describing how their AI models work along with a table listing species used for model training and performance metrics for each species, which users can consult here: <a href="https://www.wildlifeinsights.org/about-wildlife-insights-ai" class="uri">https://www.wildlifeinsights.org/about-wildlife-insights-ai</a>. We synthesize some of the key navigation steps and illustrate how one can evaluate performance of built-in AI models. Specifically, we provide code for comparing human classifications with model predictions for a subset of your images. This comparison will be useful to better understand how AI models are likely to perform with your particular images and whether AI may be able to provide accurate enough classification for some of your species.</p>
<p><strong>Before we get started</strong>: if you plan to compare model predictions with human classifications, you should download computer vision identifications right after uploading pictures to the WI platform (see Section <a href="wildlife-insights-wi.html#wi-performance">3.7</a>). It is important that you have a record of the WI classifications <strong>before you do any processing on your data</strong>.</p>
<div id="set-up" class="section level2">
<h2><span class="header-section-number">3.1</span> Set-up</h2>
<ul>
<li>Create an account here <a href="https://app.wildlifeinsights.org/join" class="uri">https://app.wildlifeinsights.org/join</a></li>
<li><p>In WI, you can structure your data hierarchically. Below, we provide an example structure from our camera trapping project in Colombia:</p>
<ul>
<li>Organization: University of Minnesota</li>
<li>Initiative: Wildlife monitoring in South America using camera traps.</li>
<li>Project: Large mammals Colombia.</li>
<li>Subprojects:
<ul>
<li>Jul2019-Jan2020 Deployment</li>
<li>Jan2020-Jul2020 Deployment</li>
</ul></li>
<li>Location: We use alphanumerical codes to name each camera trap location, with letters representing different areas within our study area (Figure <a href="wildlife-insights-wi.html#fig:locations">3.1</a>). Each location has its own geographical coordinates.</li>
<li>Deployment: Information for deployments include temporal record (start and end dates) of a camera trap survey within a particular location. In our example, for our location “A08” a camera trap was deployed from 2019-07-10 to 2020-01-08 (Figure <a href="wildlife-insights-wi.html#fig:deployments">3.2</a>).</li>
</ul></li>
</ul>
<p>This data structure allows you to manage multiple collaborators and data sets collected by different organizations and teams but associated with a single purpose <span class="citation">(Initiatives <a href="#ref-wi_initiatives">2021</a>)</span>. For example, an “Initiative” allows you to share a project between different organizations <span class="citation">(Initiatives <a href="#ref-wi_initiatives">2021</a>)</span> which facilitates data management and labor distribution.</p>
<p>Hierarchical data storage also might help to organize and filter subsets of images or data. For example “Projects” can contain “Subprojects” that might represent groups of deployments and/or locations. See the Glossary page for more terms found in WI <a href="https://www.wildlifeinsights.org/get-started/glossary" class="uri">https://www.wildlifeinsights.org/get-started/glossary</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:locations"></span>
<img src="input_figures/wi/locations.png" alt="Locations of camera traps mapped in the Wildlife Insights platform along with location names and geographical coordinates." width="100%" />
<p class="caption">
Figure 3.1: Locations of camera traps mapped in the Wildlife Insights platform along with location names and geographical coordinates.
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:deployments"></span>
<img src="input_figures/wi/deployments.png" alt="Deployments showing &quot;Start date&quot; and &quot;End date&quot; for each camera loaction." width="100%" />
<p class="caption">
Figure 3.2: Deployments showing “Start date” and “End date” for each camera loaction.
</p>
</div>
</div>
<div id="uploadformat-data" class="section level2">
<h2><span class="header-section-number">3.2</span> Upload/format data</h2>
<p>You can upload already labeled images (e.g., for storing and managing pictures in the cloud) or unlabeled images to be processed.</p>
<ul>
<li><p>For labeled images, you will need to (re)format images’ metadata using the WI batch upload templates and transfer images from a public URL (e.g., Google Drive) or directly to the Google Cloud Platform. See <a href="https://www.wildlifeinsights.org/get-started/upload/bulk-data-uploads" class="uri">https://www.wildlifeinsights.org/get-started/upload/bulk-data-uploads</a></p></li>
<li><p>For unlabeled images, you can upload images via the WI platform. Images will then be stored in the Google Cloud Platform and displayed in the user’s project. See <a href="https://www.wildlifeinsights.org/get-started/upload/upload-new-data" class="uri">https://www.wildlifeinsights.org/get-started/upload/upload-new-data</a></p></li>
</ul>
</div>
<div id="uploadenter-metadata" class="section level2">
<h2><span class="header-section-number">3.3</span> Upload/enter metadata</h2>
<p>Metadata, such as the time and date each picture was taken, the filename, camera trap name and Exif data (camera settings: photo exposure, ISO and aperture) are automatically read once unlabeled pictures are uploaded.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:metadat1-fig"></span>
<img src="input_figures/wi/metadata.png" alt="Picture metadata displayed after uploading an image to Wildlife Insights online platform." width="85%" />
<p class="caption">
Figure 3.3: Picture metadata displayed after uploading an image to Wildlife Insights online platform.
</p>
</div>
<p>You can provide additional metadata, including coordinates for the camera trap or other features associated with camera deployment (e.g., dates, camera height, settings, use of bait, etc.). This information can be entered manually for each deployment or you can use a CSV file formatted using the WI template for a bulk deployment upload. See the deployments guide <a href="https://www.wildlifeinsights.org/get-started/manage-metadata/deployments." class="uri">https://www.wildlifeinsights.org/get-started/manage-metadata/deployments.</a></p>
</div>
<div id="processing-images---ai-module" class="section level2">
<h2><span class="header-section-number">3.4</span> Processing images - AI module</h2>
<p>Once images are uploaded, they will be processed by WI’s AI model. Computer vision classifications will be available in the WI platform as soon as your pictures are uploaded (which can take ~ 11 minutes per 1000 pictures with a 225 Mbps internet upload speed). Additionally, after pictures are uploaded, you can download the output (see download tab in the upper right corner of Figure <a href="wildlife-insights-wi.html#fig:wiproject-fig">3.4</a>). The output will include a CSV file with the AI classifications (See Section <a href="wildlife-insights-wi.html#wi-output">3.6</a> for more information on WI output); you will receive an email with a link for downloading the output approximately 5 minutes after requesting it. <strong>Again, to facilitate evaluation of AI performance, we recommend downloading this CSV file before you do any other manipulations in the WI platform</strong>.</p>
<p>Your project in WI will include the uploaded pictures in the “Identify” tab. Species classifications will be shown whenever the confidence values associated with the AI-classifications are above 65% and 95% for species and blanks, respectively; otherwise images will get a “No CV Result” label <span class="citation">(Identifications <a href="#ref-wi_review">2021</a>)</span>. You will be able to verify if these classifications are correct, after which they will be moved to the “Catalogued” tab (Figure <a href="wildlife-insights-wi.html#fig:wiproject-fig">3.4</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:wiproject-fig"></span>
<img src="input_figures/wi/project.png" alt="WI processing module after uploading pictures." width="85%" />
<p class="caption">
Figure 3.4: WI processing module after uploading pictures.
</p>
</div>
</div>
<div id="post-ai-image-processing" class="section level2">
<h2><span class="header-section-number">3.5</span> Post-AI image processing</h2>
<p>WI provides a platform with multiple tools for reviewing images, allowing users to verify AI output. In addition, users can:</p>
<ul>
<li>Sort images by “Date taken”, “Upload date” or “Last modification” (the latter only for “Catalogued” images) (Figure <a href="wildlife-insights-wi.html#fig:wiproject-fig">3.4</a>).</li>
<li>Filter images by categories such as Subprojects, Deployments, Species, Status (e.g., Blank or Not blank) or Photos (e.g., Highlighted pictures for quick access or Not highlighted) (Figure <a href="wildlife-insights-wi.html#fig:wiproject-fig">3.4</a>).</li>
<li>Edit under- or over-exposed pictures by adjusting brightness, contrast and saturation.</li>
<li>Edit identifications using bulk actions by selecting and entering information for multiple pictures at a time (e.g., for 100 or 200 images).</li>
<li>Group images within a Burst defined by a timeframe (from 0-600 seconds) to perform bulk actions.</li>
<li>Manage collaborations for data processing by assigning different roles with different levels of data access (e.g., project owner, editor, contributor, tagger, viewer).</li>
</ul>
</div>
<div id="wi-output" class="section level2">
<h2><span class="header-section-number">3.6</span> Using AI output</h2>
<p>All the above mentioned processing tools can be used to review and verify AI output presented in the “Identify” tab. You can approve computer vision identifications or edit them in the processing module. You can also include additional identifications if more than 1 animal (of the same or different species) is present in the picture and add other identifying information (e.g., sex, age, markings for each individual) or other remarks (e.g., comments or observations) that may be useful.</p>
<p>When you download the resulting output, you will receive 4 different files that capture data related to your cameras, their deployments, and your projects (Figure <a href="wildlife-insights-wi.html#fig:wi-output-fig">3.5</a>):</p>
<ul>
<li><code>cameras.csv</code>: contains metadata related to the cameras, including camera_id, make, model, serial_number and year purchased.</li>
<li><code>deployments.csv</code>: contains deployment dates, geographical coordinates, details of camera trap placement and camera settings.</li>
<li><code>images.csv</code>: includes classifications and features recorded for each image.</li>
<li><code>projects.csv</code>: includes project details such as project objectives, licenses for metadata and images, and information about the sampling design used for camera trap deployment.</li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:wi-output-fig"></span>
<img src="input_figures/wi/output.png" alt="WI files created when you download project information and AI processed data." width="80%" />
<p class="caption">
Figure 3.5: WI files created when you download project information and AI processed data.
</p>
</div>
<p>In additional to these 4 CSV files, the folder with downloaded data will contain a tutorial for downloading images from WI and a file containing WI terms of use and privacy policy (Figure <a href="wildlife-insights-wi.html#fig:wi-output-fig">3.5</a>).</p>
<p>You can also quickly inspect AI results in the Summary tab (upper left of Figure <a href="wildlife-insights-wi.html#fig:wiproject-fig">3.4</a>). You will see a map with your camera locations and a summary of the species in your data set (Figure <a href="wildlife-insights-wi.html#fig:wi-summary-fig">3.6</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:wi-summary-fig"></span>
<img src="input_figures/wi/summary.png" alt="WI summary of images by type and identified species." width="80%" />
<p class="caption">
Figure 3.6: WI summary of images by type and identified species.
</p>
</div>
</div>
<div id="wi-performance" class="section level2">
<h2><span class="header-section-number">3.7</span> Assessing AI performance</h2>
<p>AI classification systems have been improving, but their performance is still highly variable, both across study sites and species <span class="citation">(Tabak et al. <a href="#ref-tabak_2018">2018</a>)</span>. Thus, it is extremely important to evaluate model performance with your data set. Before reviewing all the pictures and AI classifications, you can classify a subset of your pictures and compare these identifications with AI output. This step will allow you to determine how well the model is working for various species of interest and also to determine if there are particular species or locations where model performance is particularly poor.</p>
<p>Below, we demonstrate a step-by-step workflow for how to get WI output into R, join computer and human vision identifications, and estimate model performance metrics for each species. Throughout, we will use the <code>purrr</code> package in R <span class="citation">(Henry and Wickham <a href="#ref-purrr">2020</a>; R Core Team <a href="#ref-R-base">2021</a>)</span> to repeatedly apply the same function to objects in a list or column in a nested data frame efficiently and without the need for writing loops. Readers unfamiliar with <code>purrr</code> syntax, may want to view one or more of the tutorials, below, or make use of the <a href="https://github.com/rstudio/cheatsheets/blob/master/purrr.pdf">purrr cheat sheet</a>.</p>
<ul>
<li><a href="http://www.rebeccabarter.com/blog/2019-08-19_purrr/" class="uri">http://www.rebeccabarter.com/blog/2019-08-19_purrr/</a></li>
<li><a href="https://www.r-bloggers.com/2020/05/one-stop-tutorial-on-purrr-package-in-r/" class="uri">https://www.r-bloggers.com/2020/05/one-stop-tutorial-on-purrr-package-in-r/</a></li>
<li><a href="https://jennybc.github.io/purrr-tutorial/index.html" class="uri">https://jennybc.github.io/purrr-tutorial/index.html</a></li>
</ul>
<ol style="list-style-type: decimal">
<li>Right after uploading pictures to the WI platform and <strong><em>before</em></strong> doing any image processing (i.e., identification), download the WI output with the download tab (see Figure <a href="wildlife-insights-wi.html#fig:wiproject-fig">3.4</a>). WI’s computer vision identifications will be contained in the images.csv file (Figure <a href="wildlife-insights-wi.html#fig:wi-compvision-fig">3.7</a>). Save that file as <code>images_cv.csv</code>.</li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:wi-compvision-fig"></span>
<img src="input_figures/wi/compvision.png" alt="Identifications provided by computer vision" width="80%" />
<p class="caption">
Figure 3.7: Identifications provided by computer vision
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Use the WI processing module to verify a subset of your pictures (e.g., ~100,000) and either accept the computer vision identification as correct or edit the identification with the correct species label. The identified_by column presented in Figure 2.5 will change according to the new identifier (Figure <a href="wildlife-insights-wi.html#fig:wi-newid-fig">3.8</a>).</li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:wi-newid-fig"></span>
<img src="input_figures/wi/newid.png" alt="Identifications verified by a human" width="90%" />
<p class="caption">
Figure 3.8: Identifications verified by a human
</p>
</div>
<ol start="3" style="list-style-type: decimal">
<li><p>Once you finish identifying a subset of your images, download the data from WI and change the name of the images.csv file to <code>images_hv.csv</code>. Create a data folder to store your two CSV files <code>images_cv.csv</code> and <code>images_hv.csv</code> that refer to classifications of computer and human vision, respectively. We provide an example of both files with the repository associated with this guide, named <code>images_cv_jan2020_raw.csv</code> and <code>images_hv_jan2020_raw.csv</code>.</p></li>
<li><p>Process the two data files using the R code provided in the sections below.</p></li>
</ol>
<div id="reading-in-data-introduction-to-the-purrr-package" class="section level3">
<h3><span class="header-section-number">3.7.1</span> Reading in data, introduction to the Purrr package</h3>
<p>Before comparing human and computer vision we need to do some data cleaning. This cleaning includes removing duplicated uploads to the WI platform and making sure to keep a single record for each image, as WI creates multiple rows when more than one animal (or object) is identified in an image.</p>
<p>First, we load required libraries.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(tidyverse) <span class="co"># for data wrangling and visualization, includes dplyr and purrr</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">library</span>(here) <span class="co"># to allow use of relative paths</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="kw">library</span>(DT) <span class="co"># for viewing data tables</span></a></code></pre></div>
<p>Next, we tell R the path (i.e., directory name) that holds our files. We will use the <code>here</code> package <span class="citation">(Müller <a href="#ref-here">2017</a>)</span> to tell R that our files live in the “./data/wi” directory. You may, alternatively, type in the full path to the file folder or a relative path from the root directory if you are using a project in Rstudio.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="co"># Create filefolder&#39;s path. This should point to the folder name</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="co"># where you stored your CSV files downloaded from WI</span></a>
<a class="sourceLine" id="cb2-3" data-line-number="3">filesfolder &lt;-<span class="st"> </span><span class="kw">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;wi&quot;</span>) </a>
<a class="sourceLine" id="cb2-4" data-line-number="4">filesfolder</a></code></pre></div>
<pre><code>## [1] &quot;/Users/julianavelez/Documents/GitHub/Processing-Camera-Trap-Data-using-AI/data/wi&quot;</code></pre>
<p>Next, we use the <code>dir</code> function to list the files contained in the filesfolder directory.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="co"># list all your CSV files (i.e., &quot;images_cv_jan2020_raw.csv&quot; and &quot;images_hv_jan2020_raw.csv&quot;)</span></a>
<a class="sourceLine" id="cb4-2" data-line-number="2">files &lt;-<span class="st"> </span><span class="kw">dir</span>(filesfolder, <span class="dt">pattern =</span> <span class="st">&quot;*.csv&quot;</span>) </a>
<a class="sourceLine" id="cb4-3" data-line-number="3">files</a></code></pre></div>
<pre><code>## [1] &quot;images_cv_jan2020_raw.csv.zip&quot; &quot;images_hv_jan2020_raw.csv.zip&quot;</code></pre>
<p>We then use the <code>map</code> function in the <code>purrr</code> package to read in all of the files and store them in a list object named <code>mycsv</code>. The first argument to <code>map</code> is a list (here, <code>files</code>) which is “piped in” using <code>%&gt;%</code> from the <code>magrittr</code> package <span class="citation">(Bache and Wickham <a href="#ref-magrittr">2020</a>)</span>. Pipes (<code>%&gt;%</code>) provide a way to execute a sequence of data operations, organized so that the operations can be read from left to right (e.g., “Take this set of files and then read them in using <code>read_csv</code>”). The second argument to <code>map</code> is a function, in this case <code>read_csv</code>, to be applied to the list. The <code>map</code> function iterates over the two files stored in the <code>files</code> object, reads in the data files and then stores them in a new list named <code>mycsv.</code> We use <code>~</code> to refer to our function and use <code>.x</code> to refer to the list object that is passed to the function as an additional argument.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="co"># Read both CSV files</span></a>
<a class="sourceLine" id="cb6-2" data-line-number="2">mycsv &lt;-<span class="st"> </span>files <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb6-3" data-line-number="3"><span class="st">  </span><span class="kw">map</span>(<span class="op">~</span><span class="st"> </span><span class="kw">read_csv</span>(<span class="kw">file.path</span>(filesfolder, .x)))</a>
<a class="sourceLine" id="cb6-4" data-line-number="4"></a>
<a class="sourceLine" id="cb6-5" data-line-number="5"><span class="co"># Inspect how the data sets look like</span></a>
<a class="sourceLine" id="cb6-6" data-line-number="6">mycsv </a></code></pre></div>
<pre><code>## [[1]]
## # A tibble: 112,323 × 27
##     ...1 project_id deployment_id       image_id   filename location    is_blank
##    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
##  1     1    2000949 N23-Jan2020-Jul2020 45eab5c4-… 0219056… gs://large…        0
##  2     2    2000949 N23-Jan2020-Jul2020 03fe2e6d-… 0210041… gs://large…        0
##  3     3    2000949 N23-Jan2020-Jul2020 a0c07226-… 0216046… gs://large…        0
##  4     4    2000949 A08-Jan2020-Jul2020 810d0020-… 0115028… gs://large…        0
##  5     5    2000949 A08-Jan2020-Jul2020 d546edcc-… 0501078… gs://large…        0
##  6     6    2000949 A08-Jan2020-Jul2020 21ecd9a7-… 0608005… gs://large…        0
##  7     7    2000949 A08-Jan2020-Jul2020 aa2f7b21-… 0127084… gs://large…        0
##  8     8    2000949 A08-Jan2020-Jul2020 b4920b3e-… 0607005… gs://large…        0
##  9     9    2000949 N12-Jan2020-Jul2020 151a52ac-… 0615081… gs://large…        0
## 10    10    2000949 N12-Jan2020-Jul2020 897bbf5d-… 0529065… gs://large…        0
## # … with 112,313 more rows, and 20 more variables: identified_by &lt;chr&gt;,
## #   wi_taxon_id &lt;chr&gt;, class &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;,
## #   species &lt;chr&gt;, common_name &lt;chr&gt;, uncertainty &lt;lgl&gt;, timestamp &lt;dttm&gt;,
## #   age &lt;lgl&gt;, sex &lt;lgl&gt;, animal_recognizable &lt;lgl&gt;, individual_id &lt;lgl&gt;,
## #   number_of_objects &lt;dbl&gt;, individual_animal_notes &lt;lgl&gt;, highlighted &lt;lgl&gt;,
## #   markings &lt;lgl&gt;, cv_confidence &lt;dbl&gt;, license &lt;chr&gt;
## 
## [[2]]
## # A tibble: 114,237 × 27
##       X1 project_id deployment_id       image_id   filename location    is_blank
##    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
##  1     1    2000949 N25-Jan2020-Jul2020 902b671f-… 0331008… gs://large…        0
##  2     2    2000949 N23-Jan2020-Jul2020 9a430206-… 0424015… gs://large…        0
##  3     3    2000949 N29-Jan2020-Jul2020 e727dc42-… 0331028… gs://large…        0
##  4     4    2000949 A06-Jan2020-Jul2020 db3c3213-… 0602047… gs://large…        0
##  5     5    2000949 A02-Jan2020-Jul2020 c7e33138-… 0310038… gs://large…        1
##  6     6    2000949 A04-Jan2020-Jul2020 52f77e0c-… 0418003… gs://large…        0
##  7     7    2000949 A06-Jan2020-Jul2020 94a5b596-… 0302034… gs://large…        0
##  8     8    2000949 A06-Jan2020-Jul2020 063c0153-… 0619014… gs://large…        0
##  9     9    2000949 A06-Jan2020-Jul2020 4b6f9c4e-… 0625031… gs://large…        0
## 10    10    2000949 A07-Jan2020-Jul2020 15c4e9f4-… 0509024… gs://large…        0
## # … with 114,227 more rows, and 20 more variables: identified_by &lt;chr&gt;,
## #   wi_taxon_id &lt;chr&gt;, class &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;,
## #   species &lt;chr&gt;, common_name &lt;chr&gt;, uncertainty &lt;lgl&gt;, timestamp &lt;dttm&gt;,
## #   age &lt;chr&gt;, sex &lt;chr&gt;, animal_recognizable &lt;lgl&gt;, individual_id &lt;lgl&gt;,
## #   number_of_objects &lt;dbl&gt;, individual_animal_notes &lt;chr&gt;, highlighted &lt;lgl&gt;,
## #   markings &lt;chr&gt;, cv_confidence &lt;lgl&gt;, license &lt;chr&gt;</code></pre>
<p>There are many variables that we will not need when evaluating AI performance. To simplify things, we use the <code>select</code> function to only keep the variables of interest:</p>
<ul>
<li><code>deployment_id</code>: deployment name including camera location.</li>
<li><code>filename</code>: image filename.</li>
<li><code>timestamp</code>: time of a camera trigger.</li>
<li><code>image_id</code>: WI identifier for images uploaded to the platform.</li>
<li><code>common_name</code>: species’ common name labeled either by computer or human vision.</li>
<li><code>cv_confidence</code>: confidence value associated with the computer vision label.</li>
</ul>
<p>Additionally, we remove images without a classification (i.e., common_name = “NA”) and with the “Human” class, as human images in this data set predominately correspond to camera-set-up images. We inspect the final number of rows using <code>nrow()</code>.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">mycsv &lt;-<span class="st"> </span>mycsv <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb8-2" data-line-number="2"><span class="st">  </span><span class="kw">map</span>(<span class="op">~</span>.x <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb8-3" data-line-number="3"><span class="st">        </span><span class="kw">select</span>(deployment_id, filename, timestamp, image_id, common_name, cv_confidence) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb8-4" data-line-number="4"><span class="st">        </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">is.na</span>(common_name)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb8-5" data-line-number="5"><span class="st">        </span><span class="kw">filter</span>(common_name <span class="op">!=</span><span class="st"> &quot;Human&quot;</span> <span class="op">&amp;</span><span class="st"> </span>common_name <span class="op">!=</span><span class="st"> &quot;Human-Camera Trapper&quot;</span>))</a>
<a class="sourceLine" id="cb8-6" data-line-number="6"></a>
<a class="sourceLine" id="cb8-7" data-line-number="7">mycsv <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">map</span>(<span class="op">~</span>.x <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">nrow</span>())</a></code></pre></div>
<pre><code>## [[1]]
## [1] 108515
## 
## [[2]]
## [1] 106787</code></pre>
</div>
<div id="removing-duplicate-images" class="section level3">
<h3><span class="header-section-number">3.7.2</span> Removing duplicate images</h3>
<p>Before discussing how to join the two data sets corresponding to human and computer vision, we need to remove duplicated rows that might result from accidentally uploading the same image more than once to the WI platform. We can identify these duplicated uploads as they contain the same information in all the columns except for <code>image_id</code>. Figure <a href="wildlife-insights-wi.html#fig:wi-duplicated-fig">3.9</a> shows two different examples of duplicated uploads.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:wi-duplicated-fig"></span>
<img src="input_figures/wi/duplicated_uploads.png" alt="Identification of duplicated image uploads in the images.csv WI output." width="150%" />
<p class="caption">
Figure 3.9: Identification of duplicated image uploads in the images.csv WI output.
</p>
</div>
<p>We will use the information contained in <code>deployment_id</code>, <code>filename</code>, and <code>timestamp</code> to uniquely identify each image event; hereafter, we will refer to this suite of variables as key columns. To remove duplicates in our data sets, we first use the <code>group_by</code> function to group rows using these key columns and store our grouped dataframe as <code>mycsv_grouped</code>. We use the <code>summarise</code> function <span class="citation">(Wickham et al. <a href="#ref-R-dplyr">2019</a>)</span> to create a new column <code>uploads</code> that contains the count of unique <code>image_id</code> values for each group of rows. Groups that have more than one <code>image_id</code> indicate duplicated uploads (Figure <a href="wildlife-insights-wi.html#fig:wi-duplicated-fig">3.9</a>). We then filter by counts &gt; 1 to inspect duplicated images, remove duplicated rows in our data sets using the <code>unique</code> function <span class="citation">(R Core Team <a href="#ref-R-base">2021</a>)</span> and store the remaining data in the <code>no_duplicates</code> list object.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1">mycsv_grouped &lt;-<span class="st"> </span>mycsv <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb10-2" data-line-number="2"><span class="st">  </span><span class="kw">map</span>(<span class="op">~</span>.x <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb10-3" data-line-number="3"><span class="st">  </span><span class="kw">group_by</span>(deployment_id, filename, timestamp))</a>
<a class="sourceLine" id="cb10-4" data-line-number="4"></a>
<a class="sourceLine" id="cb10-5" data-line-number="5"><span class="co"># Create data set with duplicated images</span></a>
<a class="sourceLine" id="cb10-6" data-line-number="6">duplicated_images &lt;-<span class="st"> </span>mycsv_grouped <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb10-7" data-line-number="7"><span class="st">  </span><span class="kw">map</span>(<span class="op">~</span>.x <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb10-8" data-line-number="8"><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">uploads =</span> <span class="kw">length</span>(<span class="kw">unique</span>(image_id))) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># count unique ID&#39;s</span></a>
<a class="sourceLine" id="cb10-9" data-line-number="9"><span class="st">    </span><span class="kw">filter</span>(uploads <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>)) <span class="co"># for inspecting duplicated uploads</span></a>
<a class="sourceLine" id="cb10-10" data-line-number="10"></a>
<a class="sourceLine" id="cb10-11" data-line-number="11"><span class="co"># Create a data set without the duplicated images</span></a>
<a class="sourceLine" id="cb10-12" data-line-number="12">no_duplicates &lt;-<span class="st"> </span>mycsv_grouped <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb10-13" data-line-number="13"><span class="st">  </span><span class="kw">map</span>(<span class="op">~</span>.x <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb10-14" data-line-number="14"><span class="st">  </span><span class="kw">filter</span>(image_id <span class="op">==</span><span class="st"> </span><span class="kw">unique</span>(image_id)[<span class="dv">1</span>])) </a>
<a class="sourceLine" id="cb10-15" data-line-number="15"><span class="co"># This code keeps all the records that have a single image ID and keeps only</span></a>
<a class="sourceLine" id="cb10-16" data-line-number="16"><span class="co"># one record of duplicated uploads selected by indexing the first &quot;image_id&quot; within a group</span></a></code></pre></div>
</div>
<div id="images-with-multiple-observations-of-the-same-species" class="section level3">
<h3><span class="header-section-number">3.7.3</span> Images with multiple observations of the same species</h3>
<p>WI creates extra rows when you identify more than one animal per picture. Thus, it is likely that your two CSV files will slightly differ in number of rows (as is the case here). After removing duplicated records, we need to drop extra rows in the human vision data frame that result from identifying more than 1 animal of the same species in the same image. As an example, Figure <a href="wildlife-insights-wi.html#fig:wi-distinct-dets-fig">3.10</a> displays records for both a juvenile and adult Southern tamandua detected in the same image.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:wi-distinct-dets-fig"></span>
<img src="input_figures/wi/distinct_dets.png" alt="Highlighted rows represent detections of one juvenile and an adult of the Southern Tamandua in the same image." width="150%" />
<p class="caption">
Figure 3.10: Highlighted rows represent detections of one juvenile and an adult of the Southern Tamandua in the same image.
</p>
</div>
<p>We regroup the data by the key columns from before, adding <code>common_name</code>; we also add <code>cv_confidence</code> to retain this variable for later use. We then apply the <code>summarise</code> function to reduce multiple records of the same species in the same image to a single record.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1">same_sp_dets &lt;-<span class="st"> </span>no_duplicates <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb11-2" data-line-number="2"><span class="st">  </span><span class="kw">map</span>(<span class="op">~</span>.x <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb11-3" data-line-number="3"><span class="st">  </span><span class="kw">group_by</span>(deployment_id, filename, timestamp, cv_confidence, common_name) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb11-4" data-line-number="4"><span class="st">    </span><span class="kw">summarise</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># summarise rows that correspond to different animals of the same species </span></a>
<a class="sourceLine" id="cb11-5" data-line-number="5"><span class="st">    </span><span class="kw">ungroup</span>()) </a></code></pre></div>
<p>We will use the human vision data set contained in the <code>same_sp_dets</code> list object as the ground truth when evaluating model performance for all platforms reviewed in this gitbook. This list object has been saved as <code>images_hv_jan2020.csv</code> using the following code.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="kw">write_csv</span>(same_sp_dets <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pluck</span>(<span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>cv_confidence), </a>
<a class="sourceLine" id="cb12-2" data-line-number="2">          <span class="dt">file =</span> <span class="st">&quot;data/wi/processed_data/images_hv_jan2020.csv&quot;</span>)</a></code></pre></div>
<p>Now that we removed duplicated records and multiple observations of the same species in the same image, we can proceed to join the computer and human vision data sets. We will match rows using a <code>right_join</code>, specifying our key columns as unique image identifiers to pair the cases from the two data sets. This will keep all records in the human vision data set and their corresponding matches in the computer vision data set. Records that are only in the computer vision data set will be dropped from further consideration. We add either a <code>_cv</code> or <code>_hv</code> suffix to the <code>common_name</code> to indicate classification by computer and human, respectively.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1">both_visions &lt;-<span class="st"> </span>same_sp_dets <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb13-2" data-line-number="2"><span class="st">  </span><span class="kw">reduce</span>(right_join, <span class="dt">by =</span> <span class="kw">c</span>(<span class="st">&quot;filename&quot;</span>, <span class="st">&quot;deployment_id&quot;</span>, <span class="st">&quot;timestamp&quot;</span>), <span class="dt">suffix =</span> <span class="kw">c</span>(<span class="st">&quot;_cv&quot;</span>, <span class="st">&quot;_hv&quot;</span>))</a></code></pre></div>
</div>
<div id="images-with-multiple-species" class="section level3">
<h3><span class="header-section-number">3.7.4</span> Images with multiple species</h3>
<p>Similar to multiple detections of the same species, when we identify different species in the same image, these observations will be recorded in separate rows in the human vision data set (Figure <a href="wildlife-insights-wi.html#fig:wi-multiple-sp-fig">3.11</a>). When using the <code>right_join</code> to match observations from the computer and human vision data sets, some of the computer vision labels will be replicated to match the multiple rows generated for different species detected in the same image by human vision.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:wi-multiple-sp-fig"></span>
<img src="input_figures/wi/multiple_sp.png" alt="Highlighted rows represent detections of different species in the same image." width="150%" />
<p class="caption">
Figure 3.11: Highlighted rows represent detections of different species in the same image.
</p>
</div>
<p>To address this complication, we create a <code>sp_num</code> column containing the number of species per image, which can then be used to identify records with more than one species in an image <code>sp_num &gt; 1</code>. We then subset the observations that have more than 1 species in an image.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">both_visions &lt;-<span class="st"> </span>both_visions <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb14-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(deployment_id, filename, timestamp) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb14-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sp_num =</span> <span class="kw">length</span>(<span class="kw">unique</span>(common_name_hv)))</a>
<a class="sourceLine" id="cb14-4" data-line-number="4"></a>
<a class="sourceLine" id="cb14-5" data-line-number="5">multiple_sp_dets &lt;-<span class="st"> </span>both_visions <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb14-6" data-line-number="6"><span class="st">  </span><span class="kw">filter</span>(sp_num <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) </a></code></pre></div>
<p>For each of these images, we determine if there is a match between computer and human vision. We find that there are three images where AI was able to correctly identify one of the species present.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1"><span class="kw">options</span>(<span class="dt">width=</span><span class="dv">180</span>)</a>
<a class="sourceLine" id="cb15-2" data-line-number="2">multiple_sp_dets <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb15-3" data-line-number="3"><span class="st">  </span><span class="kw">filter</span>(common_name_cv <span class="op">%in%</span><span class="st"> </span>common_name_hv) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb15-4" data-line-number="4"><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb15-5" data-line-number="5"><span class="st">  </span><span class="kw">select</span>(<span class="op">!</span><span class="kw">c</span>(timestamp, deployment_id, cv_confidence_hv,  sp_num)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb15-6" data-line-number="6"><span class="st">  </span><span class="kw">print</span>(<span class="dt">width=</span><span class="ot">Inf</span>, <span class="dt">n=</span><span class="dv">1000</span>)</a></code></pre></div>
<pre><code>## # A tibble: 6 × 4
##   filename     cv_confidence_cv common_name_cv   common_name_hv           
##   &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;                    
## 1 02240652.JPG             0.77 Collared Peccary Collared Peccary         
## 2 02240652.JPG             0.77 Collared Peccary Margarita Island Capuchin
## 3 02240653.JPG             0.69 Collared Peccary Collared Peccary         
## 4 02240653.JPG             0.69 Collared Peccary Margarita Island Capuchin
## 5 02240654.JPG             0.75 Collared Peccary Collared Peccary         
## 6 02240654.JPG             0.75 Collared Peccary Margarita Island Capuchin</code></pre>
<p>We can also look at some of the records for images that had multiple species in them but AI failed to correctly identify any of them.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1">multiple_sp_dets <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb17-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span>common_name_cv <span class="op">%in%</span><span class="st"> </span>common_name_hv) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb17-3" data-line-number="3"><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb17-4" data-line-number="4"><span class="st">  </span><span class="kw">select</span>(<span class="op">!</span><span class="kw">c</span>(timestamp, deployment_id, cv_confidence_hv,  sp_num)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb17-5" data-line-number="5"><span class="st">  </span><span class="kw">head</span>(<span class="dv">10</span>)</a></code></pre></div>
<pre><code>## # A tibble: 10 × 4
##    filename     cv_confidence_cv common_name_cv common_name_hv           
##    &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;                    
##  1 06300682.JPG             0.37 No CV Result   Bos Species              
##  2 06300682.JPG             0.37 No CV Result   Domestic Horse           
##  3 06300683.JPG             0.82 No CV Result   Bos Species              
##  4 06300683.JPG             0.82 No CV Result   Domestic Horse           
##  5 02240646.JPG             0.42 No CV Result   Collared Peccary         
##  6 02240646.JPG             0.42 No CV Result   Margarita Island Capuchin
##  7 02240650.JPG             0.52 No CV Result   Collared Peccary         
##  8 02240650.JPG             0.52 No CV Result   Margarita Island Capuchin
##  9 02240651.JPG             0.64 No CV Result   Collared Peccary         
## 10 02240651.JPG             0.64 No CV Result   Margarita Island Capuchin</code></pre>
<p>We then need to decide how to treat these records. Because WI will only identify 1 species in an image, we want to give it credit when it matches one of multiple species present. We also choose to consider it a single failure when AI fails to match any of the multiple species present. Thus, we chose to create a data set that combines:</p>
<ul>
<li>records for all images that contain only 1 species</li>
<li>the matched observation whenever there are multiple species present and one of them is identified using AI</li>
<li>the first observation whenever there are multiple species present and AI fails to identify any of them</li>
</ul>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1">dataA &lt;-<span class="st"> </span>both_visions <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb19-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(sp_num <span class="op">==</span><span class="dv">1</span>)  <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb19-3" data-line-number="3"><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb19-4" data-line-number="4"><span class="st">  </span><span class="kw">drop_na</span>(common_name_hv)</a>
<a class="sourceLine" id="cb19-5" data-line-number="5"></a>
<a class="sourceLine" id="cb19-6" data-line-number="6">dataB &lt;-<span class="st"> </span>multiple_sp_dets <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb19-7" data-line-number="7"><span class="st">  </span><span class="kw">filter</span>(common_name_cv <span class="op">%in%</span><span class="st"> </span>common_name_hv) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb19-8" data-line-number="8"><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb19-9" data-line-number="9"><span class="st">  </span><span class="kw">filter</span>(common_name_cv <span class="op">==</span><span class="st"> </span>common_name_hv)<span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb19-10" data-line-number="10"><span class="st">  </span><span class="kw">drop_na</span>(common_name_hv)</a>
<a class="sourceLine" id="cb19-11" data-line-number="11"></a>
<a class="sourceLine" id="cb19-12" data-line-number="12">dataC &lt;-<span class="st"> </span>multiple_sp_dets <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb19-13" data-line-number="13"><span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span>common_name_cv <span class="op">%in%</span><span class="st"> </span>common_name_hv) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb19-14" data-line-number="14"><span class="st">  </span><span class="kw">filter</span>(<span class="kw">row_number</span>()<span class="op">==</span><span class="dv">1</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb19-15" data-line-number="15"><span class="st">  </span><span class="kw">ungroup</span>()<span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb19-16" data-line-number="16"><span class="st">  </span><span class="kw">drop_na</span>(common_name_hv)</a>
<a class="sourceLine" id="cb19-17" data-line-number="17">  </a>
<a class="sourceLine" id="cb19-18" data-line-number="18">both_visions_clean&lt;-<span class="st"> </span><span class="kw">rbind</span>(dataA,</a>
<a class="sourceLine" id="cb19-19" data-line-number="19">                            dataB, </a>
<a class="sourceLine" id="cb19-20" data-line-number="20">                            dataC)</a></code></pre></div>
</div>
<div id="summarizing-human-and-computer-vision-records-by-species" class="section level3">
<h3><span class="header-section-number">3.7.5</span> Summarizing human and computer vision records by species</h3>
<p>Next, we count the number of records of each species separately for human and computer vision. We will group the data by <code>common_name</code> and then count the number of observations using <code>n()</code> inside <code>summarise</code>. Then, we use the <code>full_join</code> function to join the species counts in computer and human vision using the <code>common_name</code> to match observations in the two data sets. Lastly, we add a suffix to the <code>common_name</code> variable to distinguish the counts of human and computer vision.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1">sp_counts_cv &lt;-<span class="st"> </span>both_visions_clean <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb20-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(common_name_cv) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb20-3" data-line-number="3"><span class="st">        </span><span class="kw">summarise</span>(<span class="dt">n =</span> <span class="kw">n</span>()) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb20-4" data-line-number="4"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">common_name =</span> common_name_cv)</a>
<a class="sourceLine" id="cb20-5" data-line-number="5"></a>
<a class="sourceLine" id="cb20-6" data-line-number="6">sp_counts_hv &lt;-<span class="st"> </span>both_visions_clean <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb20-7" data-line-number="7"><span class="st">  </span><span class="kw">group_by</span>(common_name_hv) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb20-8" data-line-number="8"><span class="st">        </span><span class="kw">summarise</span>(<span class="dt">n =</span> <span class="kw">n</span>()) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb20-9" data-line-number="9"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">common_name =</span> common_name_hv)</a>
<a class="sourceLine" id="cb20-10" data-line-number="10"></a>
<a class="sourceLine" id="cb20-11" data-line-number="11">sp_counts &lt;-<span class="st"> </span><span class="kw">full_join</span>(sp_counts_cv, sp_counts_hv, </a>
<a class="sourceLine" id="cb20-12" data-line-number="12">                       <span class="dt">by =</span> <span class="st">&quot;common_name&quot;</span>, </a>
<a class="sourceLine" id="cb20-13" data-line-number="13">                       <span class="dt">suffix =</span> <span class="kw">c</span>(<span class="st">&quot;_cv&quot;</span>, <span class="st">&quot;_hv&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb20-14" data-line-number="14"><span class="st">  </span><span class="kw">arrange</span>(common_name) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb20-15" data-line-number="15"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">common_name =</span> <span class="kw">as.factor</span>(common_name))</a></code></pre></div>
<p>You can inspect the resulting data frame with the per-species counts for the two visions (Table <a href="wildlife-insights-wi.html#tab:myDThtmltools1">3.1</a>).</p>
<div id="htmlwidget-4eb221abc6ec1eb60152" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-4eb221abc6ec1eb60152">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","69","70","71","72"],["Alouatta Species","Amazonian Motmot","Ants","Aphelocoma Species","Bird","Black Agouti","Blank","Bos Species","Bush Dog","Caprimulgidae Family","Capybara","Central American Agouti","Central American Red Brocket","Cervidae Family","Collared Peccary","Common Green Iguana","Common Opossum","Crab-eating Fox","Crestless Curassow","Dasypus Species","Domestic Cattle","Domestic Dog","Domestic Horse","Fasciated Tiger-heron","Giant Anteater","Giant Armadillo","Giant Otter","Great Curassow","Great Tinamou","Greater Long-nosed Armadillo","Grey Fox","Guineafowl Family","Insect","Jaguar","Jaguarundi","Lizards and Snakes","Lowland Tapir","Mammal","Margarita Island Capuchin","Margay","Mule Deer","Neotropical Otter","Nine-banded Armadillo","No CV Result","Northern Amazon Red Squirrel","Northern Raccoon","Ocelot","Ornate Tití Monkey","Pecari Species","Peromyscus Species","Possum Family","Puma","Razor-billed Curassow","Red Brocket","Rodent","Saimiri Species","South American Coati","Southern Tamandua","Spix's Guan","Spotted Paca","Tayra","Turkey Vulture","Turtle Order","Unknown species","Virginia Opossum","Weasel Family","White-lipped Peccary","White-nosed Coati","White-tailed Deer","Wild Boar","Wild Turkey",null],[null,null,null,1919,3,575,5248,null,null,null,null,175,4,null,11794,null,186,null,null,null,165,106,null,null,103,14,null,6,61,8,258,7,null,null,1,null,51,null,null,null,3472,null,945,73858,null,2435,18,null,null,1,null,38,28,null,null,null,5,null,null,2017,41,5,null,20,109,null,77,19,null,225,425,360],[6,268,33,null,5766,14210,20334,3580,22,114,21,null,null,900,24784,22,null,98,1523,5732,null,19,958,6,807,167,1,null,null,null,null,null,6,3,12,210,1562,11,203,20,null,6,null,null,253,null,363,49,37,null,951,131,null,134,4135,50,2890,1391,1316,5650,415,4,106,1280,null,2,3813,null,408,null,null,null]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>common_name<\/th>\n      <th>n_cv<\/th>\n      <th>n_hv<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[2,3]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<table>
<caption>
<span id="tab:myDThtmltools1">Table 3.1: </span>Counts of images classified by Wildlife Insights AI (n_cv, using a 0.65 and 0.95 confidence threshold for predicting species and blanks, respectively) and humans (n_hv) for each species in the data set.
</caption>
</table>
<p>When looking at the table of species counts, you will likely notice that you have some species that show up in the computer vision (i.e., AI) data set that are not present in the human vision data set and vice versa. Using the <code>sp_counts</code> data frame (Table <a href="wildlife-insights-wi.html#tab:myDThtmltools1">3.1</a>) calculated above, we can easily identify the species labels that are not found in both data sets. We can then simplify the table by replacing labels found only in the human vision data set as “Other_hv” and labels only found in the computer vision data set as “Other_cv”. Doing so will allow us to create a simplified confusion matrix (a matrix that shows the combinations of all predicted and true classifications used to inspect model performance).</p>
<p>We begin by creating new data sets, <code>NAcv</code> and <code>NAhv</code>, to contain the species labels that are only found in one of the two data sets.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1">NAcv &lt;-<span class="st">  </span>sp_counts <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb21-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(<span class="kw">is.na</span>(n_cv))</a>
<a class="sourceLine" id="cb21-3" data-line-number="3"></a>
<a class="sourceLine" id="cb21-4" data-line-number="4">NAhv &lt;-<span class="st"> </span>sp_counts <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb21-5" data-line-number="5"><span class="st">  </span><span class="kw">filter</span>(<span class="kw">is.na</span>(n_hv))</a></code></pre></div>
<p>We then replace species names not shared by both visions by “Other_cv” and “Other_hv” for computer and human vision, respectively, using the species labels stored in <code>NAcv</code> and <code>NAhv</code>. We use the <code>mutate</code> and <code>if_else</code> functions <span class="citation">(Wickham et al. <a href="#ref-R-dplyr">2019</a>)</span> to overwrite the original species names with these new labels.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1"><span class="co"># Replace categories within the NA&#39;s vector by &quot;Other_cv&quot; or &quot;Other_hv</span></a>
<a class="sourceLine" id="cb22-2" data-line-number="2">replace_others &lt;-<span class="st"> </span>both_visions_clean <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb22-3" data-line-number="3"><span class="st">       </span><span class="kw">mutate</span>(<span class="dt">common_name_hv =</span> <span class="kw">if_else</span>(common_name_hv <span class="op">%in%</span><span class="st"> </span>NAcv<span class="op">$</span>common_name,</a>
<a class="sourceLine" id="cb22-4" data-line-number="4">                                       <span class="st">&quot;Other_hv&quot;</span>,</a>
<a class="sourceLine" id="cb22-5" data-line-number="5">                                       <span class="kw">as.character</span>(common_name_hv)),</a>
<a class="sourceLine" id="cb22-6" data-line-number="6">              <span class="dt">common_name_cv =</span> <span class="kw">if_else</span>(common_name_cv <span class="op">%in%</span><span class="st"> </span>NAhv<span class="op">$</span>common_name,</a>
<a class="sourceLine" id="cb22-7" data-line-number="7">                                       <span class="st">&quot;Other_cv&quot;</span>,</a>
<a class="sourceLine" id="cb22-8" data-line-number="8">                                       <span class="kw">as.character</span>(common_name_cv))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb22-9" data-line-number="9"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">conf_cv =</span> cv_confidence_cv) </a>
<a class="sourceLine" id="cb22-10" data-line-number="10"><span class="co"># Both inputs in both visions and NA&#39;s vectors are characters. </span></a>
<a class="sourceLine" id="cb22-11" data-line-number="11"><span class="co"># Both true and false cases for the if_else statements have to be of the same class.</span></a></code></pre></div>
</div>
<div id="confusion-matrix-and-performance-measures" class="section level3">
<h3><span class="header-section-number">3.7.6</span> Confusion matrix and performance measures</h3>
<p>Using the <code>replace_others</code> data frame, we can estimate a confusion matrix using the <code>confusionMatrix</code> function from the <code>caret</code> package <span class="citation">(Kuhn <a href="#ref-R-caret">2021</a>)</span> and plot it using <code>ggplot2</code> <span class="citation">(Wickham et al. <a href="#ref-R-ggplot2">2018</a>)</span>. The <code>confusionMatrix</code> function requires a data argument for predicted classes and a reference for true classifications, both as factor classes and with the same factor levels. We use the <code>factor</code> and the <code>levels</code> function <span class="citation">(R Core Team <a href="#ref-R-base">2021</a>)</span> to convert common names into factor classes and assign them the same levels, respectively. We specifiy <code>mode = &quot;prec_recall&quot;</code> when calling the <code>confusionMatrix</code> function <span class="citation">(Kuhn <a href="#ref-R-caret">2021</a>)</span> to estimate the precision and recall for the WI classifications.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="kw">library</span>(caret) <span class="co"># to inspect model performance</span></a>
<a class="sourceLine" id="cb23-2" data-line-number="2"><span class="kw">library</span>(ggplot2) <span class="co"># to plot results</span></a>
<a class="sourceLine" id="cb23-3" data-line-number="3"></a>
<a class="sourceLine" id="cb23-4" data-line-number="4"><span class="co"># Create a vector containing all factor levels for both visions</span></a>
<a class="sourceLine" id="cb23-5" data-line-number="5">all_levels &lt;-<span class="st"> </span><span class="kw">append</span>(<span class="st">&quot;Other_cv&quot;</span>,</a>
<a class="sourceLine" id="cb23-6" data-line-number="6">                     <span class="kw">levels</span>(<span class="kw">factor</span>(replace_others<span class="op">$</span>common_name_hv))) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb23-7" data-line-number="7"><span class="st">  </span><span class="kw">sort</span>()</a>
<a class="sourceLine" id="cb23-8" data-line-number="8"></a>
<a class="sourceLine" id="cb23-9" data-line-number="9"><span class="co"># Assign the same factor levels to columns for computer and human vision labels.</span></a>
<a class="sourceLine" id="cb23-10" data-line-number="10"><span class="co"># Levels are assigned to &quot;character&quot; columns to avoid unwanted label changes</span></a>
<a class="sourceLine" id="cb23-11" data-line-number="11"><span class="co"># and then transformed with the &quot;factor&quot; function.</span></a>
<a class="sourceLine" id="cb23-12" data-line-number="12">replace_others<span class="op">$</span>common_name_hv &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">as.character</span>(replace_others<span class="op">$</span>common_name_hv), </a>
<a class="sourceLine" id="cb23-13" data-line-number="13">                                        <span class="dt">levels =</span> all_levels)</a>
<a class="sourceLine" id="cb23-14" data-line-number="14"></a>
<a class="sourceLine" id="cb23-15" data-line-number="15">replace_others<span class="op">$</span>common_name_cv &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">as.character</span>(replace_others<span class="op">$</span>common_name_cv), </a>
<a class="sourceLine" id="cb23-16" data-line-number="16">                                        <span class="dt">levels =</span> all_levels)</a>
<a class="sourceLine" id="cb23-17" data-line-number="17"></a>
<a class="sourceLine" id="cb23-18" data-line-number="18"><span class="co"># Estimate confusion matrix</span></a>
<a class="sourceLine" id="cb23-19" data-line-number="19">cm_wi &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(<span class="dt">data =</span> replace_others<span class="op">$</span>common_name_cv, </a>
<a class="sourceLine" id="cb23-20" data-line-number="20">                      <span class="dt">reference =</span> replace_others<span class="op">$</span>common_name_hv, </a>
<a class="sourceLine" id="cb23-21" data-line-number="21">                      <span class="dt">mode =</span> <span class="st">&quot;prec_recall&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb24-1" data-line-number="1"><span class="co"># Plot confusion matrix</span></a>
<a class="sourceLine" id="cb24-2" data-line-number="2">plot_cm_wi &lt;-<span class="st"> </span>cm_wi <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb24-3" data-line-number="3"><span class="st">  </span><span class="kw">pluck</span>(<span class="st">&quot;table&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb24-4" data-line-number="4"><span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb24-5" data-line-number="5"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">Frequency =</span> Freq) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb24-6" data-line-number="6"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Reference, <span class="dt">y=</span>Prediction, <span class="dt">fill=</span>Frequency)) <span class="op">+</span><span class="st"> </span><span class="co"># define axes</span></a>
<a class="sourceLine" id="cb24-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_raster</span>() <span class="op">+</span><span class="st"> </span><span class="co"># specifies a tile plot</span></a>
<a class="sourceLine" id="cb24-8" data-line-number="8"><span class="st">  </span><span class="kw">scale_fill_gradient</span>(<span class="dt">low =</span> <span class="st">&quot;#D6EAF8&quot;</span>,<span class="dt">high =</span> <span class="st">&quot;#2E86C1&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="co"># color scales</span></a>
<a class="sourceLine" id="cb24-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> Frequency), <span class="dt">size =</span> <span class="fl">1.5</span>) <span class="op">+</span><span class="co"># size for matrix counts</span></a>
<a class="sourceLine" id="cb24-10" data-line-number="10"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;bottom&quot;</span>,</a>
<a class="sourceLine" id="cb24-11" data-line-number="11">        <span class="dt">axis.text.x =</span> <span class="kw">element_text</span>(<span class="dt">angle =</span> <span class="dv">90</span>), <span class="co"># define angle for x axis text)</span></a>
<a class="sourceLine" id="cb24-12" data-line-number="12">        <span class="dt">legend.text =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">7</span>))</a>
<a class="sourceLine" id="cb24-13" data-line-number="13"></a>
<a class="sourceLine" id="cb24-14" data-line-number="14">plot_cm_wi</a></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:confmat"></span>
<img src="02-wi_files/figure-html/confmat-1.png" alt="Confusion matrix applied to classfications from Wildlife Insights using a confidence threshold of 0.65 and 0.95 for species and blanks, respectively." width="100%" />
<p class="caption">
Figure 3.12: Confusion matrix applied to classfications from Wildlife Insights using a confidence threshold of 0.65 and 0.95 for species and blanks, respectively.
</p>
</div>
<p>Now we can use the confusion matrix to estimate model performance metrics including accuracy, precision, recall and F-1 score (See Chapter <a href="introduction.html#introduction">1</a> for metrics description).</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1">(overall_accuracy &lt;-<span class="st"> </span>cm_wi <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb25-2" data-line-number="2"><span class="st">  </span><span class="kw">pluck</span>(<span class="st">&quot;overall&quot;</span>, <span class="st">&quot;Accuracy&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb25-3" data-line-number="3"><span class="st">  </span><span class="kw">round</span>(., <span class="dv">2</span>))</a></code></pre></div>
<pre><code>## [1] 0.16</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1">classes_metrics &lt;-<span class="st"> </span>cm_wi <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb27-2" data-line-number="2"><span class="st">  </span><span class="kw">pluck</span>(<span class="st">&quot;byClass&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb27-3" data-line-number="3"><span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb27-4" data-line-number="4"><span class="st">  </span><span class="kw">select</span>(Precision, Recall, F1) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb27-5" data-line-number="5"><span class="st">  </span><span class="kw">rownames_to_column</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb27-6" data-line-number="6"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">species =</span> rowname) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb27-7" data-line-number="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="kw">across</span>(is.numeric, <span class="op">~</span><span class="kw">round</span>(., <span class="dv">2</span>)))</a>
<a class="sourceLine" id="cb27-8" data-line-number="8"></a>
<a class="sourceLine" id="cb27-9" data-line-number="9">classes_metrics<span class="op">$</span>species &lt;-<span class="st"> </span><span class="kw">str_remove</span>(<span class="dt">string =</span> classes_metrics<span class="op">$</span>species, <span class="dt">pattern =</span> <span class="st">&quot;Class: &quot;</span>)</a></code></pre></div>
<div id="htmlwidget-e5f95004d510928b22cd" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-e5f95004d510928b22cd">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19"],["Bird","Black Agouti","Blank","Collared Peccary","Domestic Dog","Giant Anteater","Giant Armadillo","Jaguarundi","Lowland Tapir","Ocelot","Other_cv","Other_hv","Puma","South American Coati","Spotted Paca","Tayra","Turkey Vulture","Unknown species","White-lipped Peccary"],[1,1,0.67,0.9,0.01,1,0.93,0,0.98,0.94,0,null,0.95,1,1,0.95,0,0.2,0.97],[0,0.04,0.17,0.43,0.05,0.13,0.08,0,0.03,0.05,null,0,0.27,0,0.36,0.09,0,0,0.02],[0,0.08,0.27,0.58,0.02,0.23,0.14,null,0.06,0.09,null,null,0.43,0,0.52,0.17,null,0.01,0.04]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>species<\/th>\n      <th>Precision<\/th>\n      <th>Recall<\/th>\n      <th>F1<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[2,3,4]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<table>
<caption>
<span id="tab:myDThtmltools1">Table 3.1: </span>Model performance metrics for each species in the data set, for a confidence threshold of 0.65 and 0.95 for species and blanks, respectively.
</caption>
</table>
</div>
<div id="confidence-thresholds" class="section level3">
<h3><span class="header-section-number">3.7.7</span> Confidence thresholds</h3>
<p>Finally, we define a function that allows us to inspect how precision and recall change when different confidence thresholds are established for assigning a species label by computer vision (i.e., a prediction). Our function will assign an “Other_cv” label whenever the confidence for a computer vision prediction is below a user-specified confidence threshold. Higher thresholds should reduce the number of false positives but at the expense of more false negatives. We then estimate the same performance metrics for the specified confidence threshold. By repeating this process for several different thresholds, users can evaluate how precision and recall for each species change with the confidence threshold and identify a threshold that balances precision and recall for the different species.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" data-line-number="1">threshold_for_metrics &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">conf_threshold =</span> <span class="fl">0.7</span>, <span class="dt">tmp =</span> replace_others) {</a>
<a class="sourceLine" id="cb28-2" data-line-number="2">  tmp<span class="op">$</span>common_name_cv[tmp<span class="op">$</span>conf_cv <span class="op">&lt;</span><span class="st"> </span>conf_threshold] &lt;-<span class="st"> &quot;Other_cv&quot;</span> </a>
<a class="sourceLine" id="cb28-3" data-line-number="3">  <span class="co"># assign a &quot;Other_cv whenever the confidence value of a prediction</span></a>
<a class="sourceLine" id="cb28-4" data-line-number="4">  <span class="co"># (conf_cv) is lower than the threshold provided as an argument in the</span></a>
<a class="sourceLine" id="cb28-5" data-line-number="5">  <span class="co"># function</span></a>
<a class="sourceLine" id="cb28-6" data-line-number="6">  cm &lt;-<span class="st"> </span><span class="kw">confusionMatrix</span>(<span class="dt">data =</span> tmp<span class="op">$</span>common_name_cv, </a>
<a class="sourceLine" id="cb28-7" data-line-number="7">                        <span class="dt">reference =</span> tmp<span class="op">$</span>common_name_hv, </a>
<a class="sourceLine" id="cb28-8" data-line-number="8">                        <span class="dt">mode =</span> <span class="st">&quot;prec_recall&quot;</span>) </a>
<a class="sourceLine" id="cb28-9" data-line-number="9">  <span class="co"># use the confusionMatrix function from the caret package using the</span></a>
<a class="sourceLine" id="cb28-10" data-line-number="10">  <span class="co"># common_name_cv containing the new labels according to a particular</span></a>
<a class="sourceLine" id="cb28-11" data-line-number="11">  <span class="co"># confidence threshold</span></a>
<a class="sourceLine" id="cb28-12" data-line-number="12">  classes_metrics &lt;-<span class="st"> </span>cm <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># get confusion matrix</span></a>
<a class="sourceLine" id="cb28-13" data-line-number="13"><span class="st">    </span><span class="kw">pluck</span>(<span class="st">&quot;byClass&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># get metrics by class</span></a>
<a class="sourceLine" id="cb28-14" data-line-number="14"><span class="st">    </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># assign a data frame object</span></a>
<a class="sourceLine" id="cb28-15" data-line-number="15"><span class="st">    </span><span class="kw">select</span>(Precision, Recall, F1) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># select metrics of interest</span></a>
<a class="sourceLine" id="cb28-16" data-line-number="16"><span class="st">    </span><span class="kw">rownames_to_column</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># format data frame</span></a>
<a class="sourceLine" id="cb28-17" data-line-number="17"><span class="st">    </span><span class="kw">rename</span>(<span class="dt">species =</span> rowname) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># rename species column</span></a>
<a class="sourceLine" id="cb28-18" data-line-number="18"><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">conf_threshold =</span> conf_threshold)</a>
<a class="sourceLine" id="cb28-19" data-line-number="19">  classes_metrics<span class="op">$</span>species &lt;-<span class="st"> </span><span class="kw">str_remove</span>(<span class="dt">string =</span> classes_metrics<span class="op">$</span>species,</a>
<a class="sourceLine" id="cb28-20" data-line-number="20">                                        <span class="dt">pattern =</span> <span class="st">&quot;Class: &quot;</span>) </a>
<a class="sourceLine" id="cb28-21" data-line-number="21"></a>
<a class="sourceLine" id="cb28-22" data-line-number="22">    <span class="kw">return</span>(classes_metrics) <span class="co"># return a data frame with metrics for every species</span></a>
<a class="sourceLine" id="cb28-23" data-line-number="23">}</a></code></pre></div>
<p>Before demonstrating this approach, we first identify the species that have more than 50 records.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1"><span class="co"># Labels for prevalent species</span></a>
<a class="sourceLine" id="cb29-2" data-line-number="2">sp_plots &lt;-<span class="st"> </span>sp_counts <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb29-3" data-line-number="3"><span class="st">  </span><span class="kw">filter</span>(n_cv <span class="op">&gt;</span><span class="st"> </span><span class="dv">50</span> <span class="op">&amp;</span><span class="st"> </span>n_hv <span class="op">&gt;</span><span class="st"> </span><span class="dv">50</span> <span class="op">&amp;</span><span class="st"> </span>common_name <span class="op">!=</span><span class="st"> &quot;Blank&quot;</span>)</a>
<a class="sourceLine" id="cb29-4" data-line-number="4"><span class="kw">kable</span>(sp_plots, </a>
<a class="sourceLine" id="cb29-5" data-line-number="5">      <span class="dt">caption=</span> <span class="st">&quot;Species with at least 50 records in the human and computer vision data sets.&quot;</span>)</a></code></pre></div>
<table>
<caption><span id="tab:prevspec">Table 3.2: </span>Species with at least 50 records in the human and computer vision data sets.</caption>
<thead>
<tr class="header">
<th align="left">common_name</th>
<th align="right">n_cv</th>
<th align="right">n_hv</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Black Agouti</td>
<td align="right">575</td>
<td align="right">14210</td>
</tr>
<tr class="even">
<td align="left">Collared Peccary</td>
<td align="right">11794</td>
<td align="right">24784</td>
</tr>
<tr class="odd">
<td align="left">Giant Anteater</td>
<td align="right">103</td>
<td align="right">807</td>
</tr>
<tr class="even">
<td align="left">Lowland Tapir</td>
<td align="right">51</td>
<td align="right">1562</td>
</tr>
<tr class="odd">
<td align="left">Spotted Paca</td>
<td align="right">2017</td>
<td align="right">5650</td>
</tr>
<tr class="even">
<td align="left">White-lipped Peccary</td>
<td align="right">77</td>
<td align="right">3813</td>
</tr>
</tbody>
</table>
<p>Let’s look at the distribution of confidence values associated with these species using the <code>geom_bar</code> function <span class="citation">(Wickham et al. <a href="#ref-R-ggplot2">2018</a>)</span>.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1"><span class="co"># Plot confidence values </span></a>
<a class="sourceLine" id="cb30-2" data-line-number="2">replace_others <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb30-3" data-line-number="3"><span class="st">  </span><span class="kw">filter</span>(common_name_cv <span class="op">%in%</span><span class="st"> </span>sp_plots<span class="op">$</span>common_name <span class="op">&amp;</span><span class="st"> </span>common_name_hv <span class="op">%in%</span><span class="st"> </span>sp_plots<span class="op">$</span>common_name)  <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb30-4" data-line-number="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(conf_cv, <span class="dt">group =</span> common_name_cv, <span class="dt">colour =</span> common_name_cv)) <span class="op">+</span></a>
<a class="sourceLine" id="cb30-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_bar</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb30-6" data-line-number="6"><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>common_name_cv, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb30-7" data-line-number="7"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Empirical distribution&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;Confidence values&quot;</span>)<span class="op">+</span></a>
<a class="sourceLine" id="cb30-8" data-line-number="8"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;bottom&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb30-9" data-line-number="9"><span class="st">  </span><span class="kw">scale_color_viridis_d</span>()</a></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-13"></span>
<img src="02-wi_files/figure-html/unnamed-chunk-13-1.png" alt="Distribution of confidence values associated with species that have more than 50 records." width="864" />
<p class="caption">
Figure 3.13: Distribution of confidence values associated with species that have more than 50 records.
</p>
</div>
<p>We can see that the distribution of confidence values is left skewed for the collared peccary, giant anteater, and spotted paca, with most records having high confidence values suggesting that the AI prediction is presumed to be correct most of the time. By contrast, the black agouti, lowland tapir and the white-lipped peccary have more uniform distributions with a higher number of records that have confidence values below 0.80.</p>
<p>Let’s estimate model performance metrics for confidence values ranging from 0.65 to 0.99 using the map_df function <span class="citation">(Henry and Wickham <a href="#ref-purrr">2020</a>)</span> . The map_df function <span class="citation">(Henry and Wickham <a href="#ref-purrr">2020</a>)</span> returns a dataframe object. Once we get a dataframe of model performance metrics for a range of confidence values, we can plot the results using the <code>ggplot2</code> package <span class="citation">(Wickham et al. <a href="#ref-R-ggplot2">2018</a>)</span>.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1">conf_vector =<span class="st"> </span><span class="kw">seq</span>(<span class="fl">0.65</span>, <span class="fl">0.99</span>, <span class="dt">length=</span><span class="dv">100</span>)</a>
<a class="sourceLine" id="cb31-2" data-line-number="2">metrics_all_confs &lt;-<span class="st"> </span><span class="kw">map_df</span>(conf_vector, threshold_for_metrics, <span class="dt">tmp =</span> replace_others)</a></code></pre></div>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" data-line-number="1"><span class="co"># Plot Precision and Recall</span></a>
<a class="sourceLine" id="cb32-2" data-line-number="2">metrics_all_confs &lt;-<span class="st"> </span>metrics_all_confs <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb32-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate_if</span>(is.numeric, round, <span class="dt">digits =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb32-4" data-line-number="4"></a>
<a class="sourceLine" id="cb32-5" data-line-number="5">prec_rec_wi &lt;-<span class="st"> </span>metrics_all_confs <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb32-6" data-line-number="6"><span class="st">    </span><span class="kw">filter</span>(species <span class="op">%in%</span><span class="st"> </span>sp_plots<span class="op">$</span>common_name) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb32-7" data-line-number="7"><span class="st">  </span><span class="kw">rename</span>(<span class="dt">Species =</span> species, <span class="dt">Confidence_threshold =</span> conf_threshold) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb32-8" data-line-number="8"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Recall, <span class="dt">y =</span> Precision, <span class="dt">group =</span> Species, <span class="dt">colour =</span> Species)) <span class="op">+</span></a>
<a class="sourceLine" id="cb32-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">size =</span> Confidence_threshold)) <span class="op">+</span></a>
<a class="sourceLine" id="cb32-10" data-line-number="10"><span class="st">  </span><span class="kw">scale_size</span>(<span class="dt">range =</span> <span class="kw">c</span>(<span class="fl">0.6</span>,<span class="dv">3</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb32-11" data-line-number="11"><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Recall&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Precision&quot;</span>, ) <span class="op">+</span></a>
<a class="sourceLine" id="cb32-12" data-line-number="12"><span class="st">  </span><span class="kw">scale_color_viridis_d</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb32-13" data-line-number="13"><span class="st">  </span><span class="kw">geom_line</span>()</a>
<a class="sourceLine" id="cb32-14" data-line-number="14"></a>
<a class="sourceLine" id="cb32-15" data-line-number="15">prec_rec_wi</a></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:thresholds"></span>
<img src="02-wi_files/figure-html/thresholds-1.png" alt="Precision and recall for different confidence thresholds for species with at least 50 records. Point sizes represent the confidence thresholds used to accept AI predictions." width="100%" />
<p class="caption">
Figure 3.14: Precision and recall for different confidence thresholds for species with at least 50 records. Point sizes represent the confidence thresholds used to accept AI predictions.
</p>
</div>
<p>We see that as we increase the confidence threshold, precision usually increases and recall decreases (Figure <a href="wildlife-insights-wi.html#fig:thresholds">3.14</a>). Ideally, we would like AI to have high precision and recall, though the latter is likely to be more important in most cases. Remember that precision tells us the probability that the species is truly present when AI identifies the species as being present in an image (Chapter <a href="introduction.html#introduction">1</a>). If AI suffers from low precision, then we may have to manually review photos that AI tags as having species present in order to remove false positives. Recall, on the other hand, tells us how likely AI is to find a species in the image when it is truly present. If AI suffers from low recall, then it will miss many photos containing images of species that are truly present. To remedy this problem, we would need to review images where AI says the species is absent in order to reduce false negatives. For this particular data set, AI would be most useful for classifying collared peccaries and spotted pacas. For example, we can be confident that WI is correctly labeling collared peccaries, with a precision of 90% at a 43% recall, using a 0.65 confidence threshold (Figure <a href="wildlife-insights-wi.html#fig:thresholds">3.14</a>). The collared peccary is the most abundant species in the data set (representing 22% of the animal records) and AI could be used to catch 43% of the records of this species. We can also be very confident that WI is correctly labeling spotted pacas (precision of 100%, and it will help us to spot 36% of the actual records for the species, also using a 0.65 confidence threshold). Yet, the low recall for all species suggests that we will still have to view all images to identify other records of animals that are not detected by WI.</p>
</div>
</div>
<div id="conclusions" class="section level2">
<h2><span class="header-section-number">3.8</span> Conclusions</h2>
<p>We have seen how to set up a project, upload and process camera trap photos using WI’s platform. Additionally we provided R code for evaluating per-species model performance for different confidence thresholds. Although we found that WI was able to classify some species with high levels of precision, recall values were typically low; thus, experts will still need to review images to find the animals missed by computer vision.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-ahumada_wi">
<p>Ahumada, Jorge A., Eric Fegraus, Tanya Birch, Nicole Flores, Roland Kays, Timothy G. O’Brien, Jonathan Palmer, et al. 2019. “Wildlife Insights: A Platform to Maximize the Potential of Camera Trap and Other Passive Sensor Wildlife Data for the Planet.” Journal Article. <em>Environmental Conservation</em> 47 (1): 1–6. <a href="https://doi.org/10.1017/S0376892919000298">https://doi.org/10.1017/S0376892919000298</a>.</p>
</div>
<div id="ref-magrittr">
<p>Bache, Stefan Milton, and Hadley Wickham. 2020. <em>Magrittr: A Forward-Pipe Operator for R</em>. <a href="https://CRAN.R-project.org/package=magrittr">https://CRAN.R-project.org/package=magrittr</a>.</p>
</div>
<div id="ref-purrr">
<p>Henry, Lionel, and Hadley Wickham. 2020. <em>Purrr: Functional Programming Tools</em>. <a href="https://CRAN.R-project.org/package=purrr">https://CRAN.R-project.org/package=purrr</a>.</p>
</div>
<div id="ref-wi_review">
<p>Identifications, Wildlife Insights. 2021. “Review Identifications. Wildlife Insights Getting Started Guide.” Web Page. <a href="https://www.wildlifeinsights.org/get-started/review-identifications#a0">https://www.wildlifeinsights.org/get-started/review-identifications#a0</a>.</p>
</div>
<div id="ref-wi_initiatives">
<p>Initiatives, Wildlife Insights. 2021. “Initiatives. Wildlife Insights Getting Started Guide.” Web Page. <a href="https://www.wildlifeinsights.org/get-started/basics/initiatives">https://www.wildlifeinsights.org/get-started/basics/initiatives</a>.</p>
</div>
<div id="ref-R-caret">
<p>Kuhn, Max. 2021. <em>Caret: Classification and Regression Training</em>. <a href="https://CRAN.R-project.org/package=caret">https://CRAN.R-project.org/package=caret</a>.</p>
</div>
<div id="ref-here">
<p>Müller, Kirill. 2017. <em>Here: A Simpler Way to Find Your Files</em>. <a href="https://CRAN.R-project.org/package=here">https://CRAN.R-project.org/package=here</a>.</p>
</div>
<div id="ref-R-base">
<p>R Core Team. 2021. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.</p>
</div>
<div id="ref-tabak_2018">
<p>Tabak, Michael A., Mohammad S. Norouzzadeh, David W. Wolfson, Steven J. Sweeney, Kurt C. Vercauteren, Nathan P. Snow, Joseph M. Halseth, et al. 2018. “Machine Learning to Classify Animal Species in Camera Trap Images: Applications in Ecology.” Journal Article. <em>Methods in Ecology and Evolution</em> 10 (4): 585–90. <a href="https://doi.org/10.1111/2041-210x.13120">https://doi.org/10.1111/2041-210x.13120</a>.</p>
</div>
<div id="ref-R-ggplot2">
<p>Wickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, and Kara Woo. 2018. <em>Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics</em>. <a href="https://CRAN.R-project.org/package=ggplot2">https://CRAN.R-project.org/package=ggplot2</a>.</p>
</div>
<div id="ref-R-dplyr">
<p>Wickham, Hadley, Romain François, Lionel Henry, and Kirill Müller. 2019. <em>Dplyr: A Grammar of Data Manipulation</em>. <a href="https://CRAN.R-project.org/package=dplyr">https://CRAN.R-project.org/package=dplyr</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="camera-trap-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="megadetector---microsoft-ai.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-wi.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["CTWorkflows.pdf", "CTWorkflows.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
